{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7II68klE8rVe"
      },
      "source": [
        "# Distributed DQN Anakin Agent in `Jumanji` using `flashbax`\n",
        "### [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/instadeepai/flashbax/blob/main/examples/anakin_dqn_example.ipynb)\n",
        "\n",
        "Adapted from [Gymnax Example](https://colab.research.google.com/github/RobertTLange/gymnax/blob/main/examples/01_anakin.ipynb) and DeepMind's [Example Colab](https://colab.research.google.com/drive/1974D-qP17fd5mLxy6QZv-ic4yxlPJp-G?usp=sharing#scrollTo=lhnJkrYLOvcs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n5mRcoAF8rVj",
        "outputId": "877e7822-162c-499c-a9e6-d0a7838faa4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following devices are available:  [CpuDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "import flashbax as fbx\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import jax\n",
        "from jax import random, lax\n",
        "from jax import numpy as jnp\n",
        "from tqdm.auto import tqdm\n",
        "import jax.numpy as jnp\n",
        "import haiku as hk\n",
        "import optax\n",
        "import rlax\n",
        "import timeit\n",
        "import distrax\n",
        "import chex\n",
        "from jumanji.wrappers import AutoResetWrapper\n",
        "import jumanji\n",
        "\n",
        "print(\"The following devices are available: \", jax.devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***Observation***\n",
        "The observation given to the agent provides information regarding the weights and the values of all the items, as well as, which items have been packed into the knapsack.\n",
        "* ``weights``: jax array (float) of shape (num_items,), array of weights of the items to be packed into the knapsack.\n",
        "* ``values``: jax array (float) of shape (num_items,), array of values of the items to be packed into the knapsack.\n",
        "* ``packed_items``: jax array (bool) of shape (num_items,), array of binary values denoting which items are already packed into the knapsack.\n",
        "* ``action_mask``: jax array (bool) of shape (num_items,), array of binary values denoting which items can be packed into the knapsack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aM1GJ_Pf8rVk"
      },
      "outputs": [],
      "source": [
        "@chex.dataclass(frozen=True)\n",
        "class TimeStep:\n",
        "    observation: chex.Array\n",
        "    action: chex.Array\n",
        "    discount: chex.Array\n",
        "    reward: chex.Array\n",
        "\n",
        "\n",
        "@chex.dataclass(frozen=True)\n",
        "class Params:\n",
        "    online: hk.Params\n",
        "    target: hk.Params\n",
        "    update_count: int\n",
        "\n",
        "def process_observation(timestep: TimeStep) -> jnp.ndarray:\n",
        "    \"\"\"Concatenates and flatten the observation\"\"\"\n",
        "    return jnp.concatenate(\n",
        "        [\n",
        "            timestep.observation.coordinates.flatten(),\n",
        "            jnp.expand_dims(timestep.observation.position, 0),\n",
        "            # timestep.observation.trajectory,\n",
        "            timestep.observation.action_mask,\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_network_fn(num_outputs: int):\n",
        "    def network_fn(obs: chex.Array) -> chex.Array:\n",
        "        \"\"\"Outputs action logits.\"\"\"\n",
        "        network = hk.Sequential(\n",
        "            [\n",
        "            hk.Linear(256),\n",
        "            jax.nn.relu,\n",
        "            hk.Linear(128),\n",
        "            jax.nn.relu,\n",
        "            hk.Linear(num_outputs),\n",
        "            ]\n",
        "        )\n",
        "        return network(obs)\n",
        "\n",
        "    return hk.without_apply_rng(hk.transform(network_fn))\n",
        "\n",
        "def get_learner_fn(\n",
        "    env,\n",
        "    forward_pass,\n",
        "    buffer_fn,\n",
        "    opt_update,\n",
        "    rollout_len,\n",
        "    agent_discount,\n",
        "    iterations,\n",
        "    target_period,\n",
        "    epsilon_schedule_fn,\n",
        "    sgd_steps_per_rollout,\n",
        "):\n",
        "    \"\"\"Returns a learner function that can be used to update parameters.\"\"\"\n",
        "\n",
        "    def rollout_fn(params_state, outer_rng, env_state, env_timestep):\n",
        "        \"\"\"Collects a trajectory from the environment.\"\"\"\n",
        "        def step_fn(env_data, rng):\n",
        "            \"\"\"Steps the environment and collects transition data.\"\"\"\n",
        "            (env_state, env_timestep, params_state) = env_data\n",
        "            obs_tm1 = process_observation(env_timestep)\n",
        "            d_tm1 = env_timestep.discount\n",
        "            q_values_tm1 = forward_pass(params_state.online, jnp.expand_dims(obs_tm1, 0))\n",
        "            a_tm1_dist = distrax.EpsilonGreedy(preferences=q_values_tm1[0], epsilon=epsilon_schedule_fn(params_state.update_count))\n",
        "            a_tm1 = a_tm1_dist.sample(seed=rng)\n",
        "            new_env_state, new_env_timestep = env.step(env_state, a_tm1)  #\n",
        "            r_t = new_env_timestep.reward\n",
        "            return (\n",
        "                new_env_state,\n",
        "                new_env_timestep,\n",
        "                params_state,\n",
        "            ), TimeStep(  # return env state and transition data.\n",
        "                observation=obs_tm1, action=a_tm1, discount=d_tm1, reward=r_t\n",
        "            ) # We line up the observation with its discount, not the discount of the next observation as is usually seen.\n",
        "              # This is so that we know in a transition that discount[1] is the discount of the next observation.\n",
        "              # e.g. indexing is v[t] = reward[t] + discount[t+1]*value[t+1]\n",
        "              # Switching to Sutton and Barto's notation, we would have v[t] = reward[t+1] + discount[t+1]*value[t+1]\n",
        "              # To do this, we would add r_tm1 = env_timestep.reward to the TimeStep dataclass, not the new_env_timestep.reward\n",
        "\n",
        "        step_rngs = jax.random.split(outer_rng, rollout_len)\n",
        "        (env_state, env_timestep, params_state), rollout = lax.scan(\n",
        "            step_fn, (env_state, env_timestep, params_state), step_rngs\n",
        "        )  # trajectory.\n",
        "\n",
        "        return rollout, env_state, env_timestep\n",
        "\n",
        "    def loss_fn(params, target_params, batch):\n",
        "        \"\"\"Computes the loss for a single batch.\"\"\"\n",
        "        # For ease of reading\n",
        "        o_tm1 = batch.first.observation\n",
        "        a_tm1 = batch.first.action.astype(jnp.int32)\n",
        "        r_t = batch.first.reward\n",
        "        d_t = agent_discount * batch.second.discount\n",
        "        o_t = batch.second.observation\n",
        "        # Compute Q-values for current and next states.\n",
        "        q_tm1 = forward_pass(params, o_tm1)\n",
        "        q_t = forward_pass(target_params, o_t)\n",
        "        q_t_select = forward_pass(params, o_t)\n",
        "        # Compute the TD-error.\n",
        "        td_error = jax.vmap(\n",
        "            rlax.double_q_learning\n",
        "        )(  # compute multi-step temporal diff error.\n",
        "            q_tm1=q_tm1,  # predictions.\n",
        "            a_tm1=a_tm1,  # actions.\n",
        "            r_t=r_t,  # rewards.\n",
        "            discount_t=d_t,  # discount.\n",
        "            q_t_value=q_t,  # target values.\n",
        "            q_t_selector=q_t_select,  # selector values.\n",
        "        )\n",
        "        return jnp.mean(jnp.square(td_error))\n",
        "\n",
        "    def update_fn(\n",
        "        params_state: Params, buffer_state, opt_state, rng, env_state, env_timestep\n",
        "    ):\n",
        "        \"\"\"Updates the parameters of the agent.\"\"\"\n",
        "        rng, rollout_rng, update_rng = random.split(rng, 3)\n",
        "\n",
        "        data_rollout, new_env_state, new_env_timestep = rollout_fn(\n",
        "            params_state, rollout_rng, env_state, env_timestep\n",
        "        )  # collect trajectory from environment. This could be one step, or many steps.\n",
        "\n",
        "        buffer_state = buffer_fn.add(buffer_state, data_rollout)  # store trajectory in buffer.\n",
        "\n",
        "        def sgd_step(carry, rng):\n",
        "            \"\"\"Performs a single SGD step.\"\"\"\n",
        "            params_state, opt_state, buffer_state = carry\n",
        "\n",
        "            batch = buffer_fn.sample(buffer_state, rng).experience  # sample batch from buffer.\n",
        "\n",
        "            params, target_params = params_state.online, params_state.target\n",
        "            grads = jax.grad(loss_fn)(  # compute gradient on a single trajectory.\n",
        "                params, target_params, batch\n",
        "            )\n",
        "            grads = lax.pmean(grads, axis_name=\"j\")  # reduce mean across cores.\n",
        "            grads = lax.pmean(grads, axis_name=\"i\")  # reduce mean across batch.\n",
        "            updates, new_opt_state = opt_update(grads, opt_state)  # transform grads.\n",
        "            new_params = optax.apply_updates(params, updates)  # update parameters.\n",
        "            target_params = optax.periodic_update(  # update target parameters.\n",
        "                new_params, target_params, params_state.update_count + 1, target_period\n",
        "            )\n",
        "            new_params_state = Params(  # update parameters state.\n",
        "                online=new_params,\n",
        "                target=target_params,\n",
        "                update_count=params_state.update_count + 1,\n",
        "            )\n",
        "            return (new_params_state, new_opt_state, buffer_state), None\n",
        "\n",
        "        real_update_fn = lambda p_state, o_state, b_state, rng: jax.lax.scan(sgd_step, (p_state, o_state, b_state), jax.random.split(rng, sgd_steps_per_rollout))[0]\n",
        "        fake_update_fn = lambda p_state, o_state, b_state, _: (p_state, o_state, b_state)\n",
        "\n",
        "        new_params_state, new_opt_state, buffer_state = jax.lax.cond(  # conditional update.\n",
        "            buffer_fn.can_sample(buffer_state),  # if buffer can sample.\n",
        "            real_update_fn,  # perform update.\n",
        "            fake_update_fn,  # else do nothing.\n",
        "            params_state,\n",
        "            opt_state,\n",
        "            buffer_state,\n",
        "            update_rng,\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            new_params_state,\n",
        "            buffer_state,\n",
        "            new_opt_state,\n",
        "            rng,\n",
        "            new_env_state,\n",
        "            new_env_timestep,\n",
        "        )\n",
        "\n",
        "    def learner_fn(\n",
        "        params_state: Params, buffer_state, opt_state, rngs, env_states, env_timesteps\n",
        "    ):\n",
        "        \"\"\"Performs multiple SGD steps.\"\"\"\n",
        "        batched_update_fn = jax.vmap(\n",
        "            update_fn, axis_name=\"j\"\n",
        "        )  # vectorize across batch.\n",
        "\n",
        "        def iterate_fn(_, val):  # repeat many times to avoid going back to Python.\n",
        "            params_state, buffer_state, opt_state, rngs, env_states, env_timesteps = val\n",
        "            return batched_update_fn(\n",
        "                params_state, buffer_state, opt_state, rngs, env_states, env_timesteps\n",
        "            )\n",
        "\n",
        "        return lax.fori_loop(\n",
        "            0,\n",
        "            iterations,\n",
        "            iterate_fn,\n",
        "            (params_state, buffer_state, opt_state, rngs, env_states, env_timesteps),\n",
        "        )\n",
        "\n",
        "    return learner_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWdQogrA8rVl"
      },
      "source": [
        "### Create Experiment Fns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g6yNZahR8rVl"
      },
      "outputs": [],
      "source": [
        "def set_up_experiment(\n",
        "    env,\n",
        "    batch_size,\n",
        "    step_size,\n",
        "    seed,\n",
        "    buffer_size,\n",
        "    epsilon_init,\n",
        "    epsilon_final,\n",
        "    epsilon_steps,\n",
        "):\n",
        "    \"\"\"Sets up the experiment.\"\"\"\n",
        "    cores_count = len(jax.devices())  # get available TPU cores.\n",
        "    network = get_network_fn(env.action_spec().num_values)  # define network.\n",
        "    optim = optax.adam(step_size)  # define optimiser.\n",
        "\n",
        "    rng, rng_e, rng_p = random.split(random.PRNGKey(seed), num=3)  # prng keys.\n",
        "    _, timestep = env.reset(rng_e)\n",
        "    obs = process_observation(timestep)\n",
        "    dummy_obs = jnp.expand_dims(obs, 0)  # dummy for net init.\n",
        "    params = network.init(rng_p, dummy_obs)  # initialise params.\n",
        "    opt_state = optim.init(params)  # initialise optimiser stats.\n",
        "    buffer_fn = fbx.make_flat_buffer(\n",
        "        max_length=buffer_size,\n",
        "        min_length=batch_size,\n",
        "        sample_batch_size=batch_size,\n",
        "        add_sequences=True,\n",
        "        add_batch_size=None,\n",
        "    )\n",
        "    buffer_state = buffer_fn.init(\n",
        "        TimeStep(\n",
        "            observation=obs,\n",
        "            action=jnp.zeros((), dtype=jnp.int32),\n",
        "            reward=jnp.zeros(()),\n",
        "            discount=jnp.zeros(()),\n",
        "        )\n",
        "    )  # initialise buffer state.\n",
        "    epsilon_schedule_fn = optax.linear_schedule(\n",
        "        epsilon_init, epsilon_final, epsilon_steps\n",
        "    )  # define epsilon schedule.\n",
        "    return (\n",
        "        cores_count,\n",
        "        network,\n",
        "        optim,\n",
        "        params,\n",
        "        opt_state,\n",
        "        buffer_fn,\n",
        "        buffer_state,\n",
        "        rng,\n",
        "        epsilon_schedule_fn,\n",
        "    )\n",
        "\n",
        "\n",
        "def get_rng_keys(cores_count, num_envs, rng):\n",
        "    \"\"\"Returns a batch of random number generator keys.\"\"\"\n",
        "    rng, *step_rngs = jax.random.split(rng, cores_count * num_envs + 1)\n",
        "    reshape = lambda x: x.reshape((cores_count, num_envs) + x.shape[1:])\n",
        "    step_rngs = reshape(jnp.stack(step_rngs))  # add dimension to pmap over.\n",
        "    return rng, step_rngs\n",
        "\n",
        "\n",
        "def broadcast_to_device_shape(\n",
        "    cores_count, num_envs, params, opt_state, buffer_state, rng\n",
        "):\n",
        "    \"\"\"Broadcasts parameters to device shape.\"\"\"\n",
        "    broadcast = lambda x: jnp.broadcast_to(x, (cores_count, num_envs) + x.shape)\n",
        "    params = jax.tree_map(broadcast, params)  # broadcast to cores and batch.\n",
        "    opt_state = jax.tree_map(broadcast, opt_state)  # broadcast to cores and batch\n",
        "    buffer_state = jax.tree_map(broadcast, buffer_state)  # broadcast to cores and batch\n",
        "    params_state = Params(\n",
        "        online=params,\n",
        "        target=params,\n",
        "        update_count=jnp.zeros(shape=(cores_count, num_envs)),\n",
        "    )\n",
        "    rng, step_rngs = get_rng_keys(cores_count, num_envs, rng)\n",
        "    return params_state, opt_state, buffer_state, step_rngs, rng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLe1Xnpa8rVm"
      },
      "source": [
        "### Create Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "03I-zWqV8rVm"
      },
      "outputs": [],
      "source": [
        "# We separate the environment into a training and evaluation environment. Training resets the environment automatically, while evaluation does not.\n",
        "env = jumanji.make(\"TSP-v1\")\n",
        "training_env = AutoResetWrapper(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Uxq0e_8rVm"
      },
      "source": [
        "### Set up Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "prlhq9Tc8rVm"
      },
      "outputs": [],
      "source": [
        "# Number of Training-Evaluation iterations\n",
        "TRAINING_EVAL_ITERS = 120\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-4\n",
        "SEED = 42\n",
        "NUM_ENVS = 8\n",
        "BUFFER_SIZE = 10_000\n",
        "ROLLOUT_LEN = 512\n",
        "SGD_STEPS_PER_ROLLOUT = 64\n",
        "TRAINING_ITERS = 20\n",
        "TARGET_PERIOD = 10\n",
        "AGENT_DISCOUNT = 0.99\n",
        "EPSILON_INIT = 1.0\n",
        "EPSILON_FINAL = 0.1\n",
        "EPSILON_STEPS = 10_000\n",
        "\n",
        "# Evaluation parameters\n",
        "NUM_EVAL_EPISODES = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U89SAavZ8rVm"
      },
      "source": [
        "### Set Up Eval Fns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ROPHsMlF8rVm",
        "outputId": "5d1d727b-a4f9-4fee-fbbf-28bd98b19ab3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ryanp\\anaconda3\\lib\\site-packages\\flashbax\\buffers\\trajectory_buffer.py:473: UserWarning: Setting max_size dynamically sets the `max_length_time_axis` to be `max_size`//`add_batch_size = 10000`.This allows one to control exactly how many timesteps are stored in the buffer.Note that this overrides the `max_length_time_axis` argument.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    cores_count,\n",
        "    network,\n",
        "    optim,\n",
        "    params,\n",
        "    opt_state,\n",
        "    buffer_fn,\n",
        "    buffer_state,\n",
        "    rng,\n",
        "    epsilon_schedule_fn,\n",
        ") = set_up_experiment(\n",
        "    env=training_env,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    step_size=LEARNING_RATE,\n",
        "    seed=SEED,\n",
        "    buffer_size=BUFFER_SIZE,\n",
        "    epsilon_steps=EPSILON_STEPS,\n",
        "    epsilon_init=EPSILON_INIT,\n",
        "    epsilon_final=EPSILON_FINAL,\n",
        ")\n",
        "\n",
        "@jax.jit\n",
        "def eval_one_episode(params, rng):\n",
        "    \"\"\"Evaluates one episode.\"\"\"\n",
        "    state, timestep = env.reset(rng)\n",
        "\n",
        "    def step(val):\n",
        "        params, state, timestep, tot_r, rng, done = val\n",
        "        rng, key_step = jax.random.split(rng)\n",
        "        obs = process_observation(timestep)\n",
        "        q_values = network.apply(params, obs[jnp.newaxis,])\n",
        "        a_t = jnp.argmax(q_values, axis=-1)[0]\n",
        "        state, timestep = env.step(state, a_t)\n",
        "        tot_r += timestep.reward\n",
        "        return (params, state, timestep, tot_r, rng, timestep.last())\n",
        "\n",
        "    params, state, timestep, tot_r, rng, done = jax.lax.while_loop(lambda val : val[5] == False, step, (params, state, timestep, 0, rng, False))\n",
        "\n",
        "    return params, tot_r\n",
        "\n",
        "@jax.jit\n",
        "def eval(params, rng):\n",
        "    \"\"\"Evaluates multiple episodes.\"\"\"\n",
        "    rngs = random.split(rng, NUM_EVAL_EPISODES)\n",
        "    params = jax.tree_map(lambda x: x[0][0], params)\n",
        "    _, tot_r = jax.lax.scan(eval_one_episode, params, rngs)\n",
        "    return tot_r.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml7RZq-08rVn"
      },
      "source": [
        "## Perform Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dVzEOidU8rVn",
        "outputId": "2d512a20-158d-46b1-e940-8e06056e3ca4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcb205993f0e40d98138d2095bbd6625",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/120 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Reward at iteration 0: -34.72391128540039\n",
            "Average Reward at iteration 2: -29.05413246154785\n",
            "Average Reward at iteration 4: -29.392778396606445\n",
            "Average Reward at iteration 6: -28.39190673828125\n",
            "Average Reward at iteration 8: -28.284271240234375\n",
            "Average Reward at iteration 10: -28.343862533569336\n",
            "Average Reward at iteration 12: -28.284271240234375\n",
            "Average Reward at iteration 14: -28.296348571777344\n",
            "Average Reward at iteration 16: -28.30266761779785\n",
            "Average Reward at iteration 18: -28.476600646972656\n",
            "Average Reward at iteration 20: -28.297225952148438\n",
            "Average Reward at iteration 22: -28.284271240234375\n",
            "Average Reward at iteration 24: -28.673200607299805\n",
            "Average Reward at iteration 26: -28.284271240234375\n",
            "Average Reward at iteration 28: -28.284271240234375\n",
            "Average Reward at iteration 30: -28.284271240234375\n",
            "Average Reward at iteration 32: -28.284271240234375\n",
            "Average Reward at iteration 34: -28.284271240234375\n",
            "Average Reward at iteration 36: -28.403045654296875\n",
            "Average Reward at iteration 38: -28.284271240234375\n",
            "Average Reward at iteration 40: -28.47921371459961\n",
            "Average Reward at iteration 42: -28.284271240234375\n",
            "Average Reward at iteration 44: -28.284271240234375\n",
            "Average Reward at iteration 46: -28.284271240234375\n",
            "Average Reward at iteration 48: -28.284271240234375\n",
            "Average Reward at iteration 50: -28.284271240234375\n",
            "Average Reward at iteration 52: -28.284271240234375\n",
            "Average Reward at iteration 54: -28.284271240234375\n",
            "Average Reward at iteration 56: -28.284271240234375\n",
            "Average Reward at iteration 58: -28.284271240234375\n",
            "Average Reward at iteration 60: -28.284271240234375\n",
            "Average Reward at iteration 62: -28.284271240234375\n",
            "Average Reward at iteration 64: -28.284271240234375\n",
            "Average Reward at iteration 66: -28.284271240234375\n",
            "Average Reward at iteration 68: -28.284271240234375\n",
            "Average Reward at iteration 70: -28.284271240234375\n",
            "Average Reward at iteration 72: -28.284271240234375\n",
            "Average Reward at iteration 74: -28.284271240234375\n",
            "Average Reward at iteration 76: -28.284271240234375\n",
            "Average Reward at iteration 78: -28.284271240234375\n",
            "Average Reward at iteration 80: -28.284271240234375\n",
            "Average Reward at iteration 82: -28.284271240234375\n",
            "Average Reward at iteration 84: -28.284271240234375\n",
            "Average Reward at iteration 86: -28.284271240234375\n",
            "Average Reward at iteration 88: -28.284271240234375\n",
            "Average Reward at iteration 90: -28.284271240234375\n",
            "Average Reward at iteration 92: -28.284271240234375\n",
            "Average Reward at iteration 94: -28.284271240234375\n",
            "Average Reward at iteration 96: -28.284271240234375\n",
            "Average Reward at iteration 98: -28.284271240234375\n",
            "Average Reward at iteration 100: -28.284271240234375\n",
            "Average Reward at iteration 102: -28.284271240234375\n",
            "Average Reward at iteration 104: -28.284271240234375\n",
            "Average Reward at iteration 106: -28.284271240234375\n",
            "Average Reward at iteration 108: -28.284271240234375\n",
            "Average Reward at iteration 110: -28.284271240234375\n",
            "Average Reward at iteration 112: -28.284271240234375\n",
            "Average Reward at iteration 114: -28.284271240234375\n",
            "Average Reward at iteration 116: -28.284271240234375\n",
            "Average Reward at iteration 118: -28.284271240234375\n"
          ]
        }
      ],
      "source": [
        "rng, *env_rngs = jax.random.split(rng, cores_count * NUM_ENVS + 1)\n",
        "env_states, env_timesteps = jax.vmap(env.reset)(jnp.stack(env_rngs))  # init envs.\n",
        "reshape = lambda x: x.reshape((cores_count, NUM_ENVS) + x.shape[1:])\n",
        "env_states = jax.tree_map(reshape, env_states)  # add dimension to pmap over.\n",
        "env_timesteps = jax.tree_map(reshape, env_timesteps)  # add dimension to pmap over.\n",
        "params_state, opt_state, buffer_state, step_rngs, rng = broadcast_to_device_shape(\n",
        "    cores_count, NUM_ENVS, params, opt_state, buffer_state, rng\n",
        ")\n",
        "\n",
        "learn = get_learner_fn(\n",
        "    env=training_env,\n",
        "    forward_pass=network.apply,\n",
        "    buffer_fn=buffer_fn,\n",
        "    opt_update=optim.update,\n",
        "    rollout_len=ROLLOUT_LEN,\n",
        "    agent_discount=AGENT_DISCOUNT,\n",
        "    iterations=TRAINING_ITERS,\n",
        "    target_period=TARGET_PERIOD,\n",
        "    epsilon_schedule_fn=epsilon_schedule_fn,\n",
        "    sgd_steps_per_rollout=SGD_STEPS_PER_ROLLOUT,\n",
        ")\n",
        "learn = jax.pmap(learn, axis_name=\"i\")  # replicate over multiple cores.\n",
        "\n",
        "\n",
        "avg_reward = []\n",
        "total_time = 0\n",
        "for training_eval_iters in tqdm(range(TRAINING_EVAL_ITERS)):\n",
        "    # Train\n",
        "    start = timeit.default_timer()\n",
        "    params_state, buffer_state, opt_state, step_rngs, env_states, env_timesteps = learn(params_state, buffer_state, opt_state, step_rngs, env_states, env_timesteps)\n",
        "    params_state = jax.tree_map(lambda x: x.block_until_ready(), params_state) # wait for params to be ready so time is accurate.\n",
        "    total_time += timeit.default_timer() - start\n",
        "    # Eval\n",
        "    rng, eval_rng = jax.random.split(rng, num=2)\n",
        "    tot_r = eval(params_state.online, eval_rng)\n",
        "    avg_reward.append(tot_r)\n",
        "    if training_eval_iters % 2 == 0:\n",
        "        print(f\"Average Reward at iteration {training_eval_iters}: {tot_r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJOLnm158rVn"
      },
      "source": [
        "## Plot Evaluation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "64YyUGSh8rVn",
        "outputId": "9d10fc7e-1ef6-426d-a6f8-69fad8773446"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGkCAYAAAAmBb/dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABLa0lEQVR4nO3deVhUZcMG8HuYGTZBAQXcF0BRwSXhNRXUNDdURDGXMnMp9z7L0tRUyhRxS9IW0zS3TEwl1AJNMdPSXEhTXNC0TBAURRFZhplzzvcHMkUsM4MwHOT+Xdd7fXFm5pxnHv14bp9VIUmSBCIiIqJKzKKiC0BERET0pBhoiIiIqNJjoCEiIqJKj4GGiIiIKj0GGiIiIqr0GGiIiIio0mOgoadOYmIiWrRogaCgIAQFBSEwMBDDhw9HdHR0offNmDEDvXv3xoABA/DCCy9gx44dBV739PQscA0A1q9fj1mzZpV5uY8dO6Yvs5+fHzp06KD/Ob/sX3zxBYKCgjBgwAD0798fS5YsQW5uLgDg448/1n9m4MCBCAwMxOjRo/Hnn3+WqjyXL1+Gv79/qT6bkZGBV155xeTPxcbGYuHChSW+5/bt2xg+fHipylWUHTt2YOvWrQCAbdu2Ye3atWV2b0Nyc3MxZswY7Nu3T38tOTkZY8eO1f8Zf/vtt0V+NiMjA61atdL/HQkKCsKvv/4KALh16xYmTJig/3tw9OjRUpexLOp77ty5iI+Pf6J7EBkkET1lbt68KbVt27bAtcTERKlHjx7Svn37JEmSpFu3bkl+fn7Srl279O9JSUmRXn75ZWnp0qX6+zRv3lzy8fGRrl27pn/funXrpJkzZ5brd1i1apU0f/78Ateio6OloUOHStnZ2ZIkSVJOTo40fvx46cMPPyz2M5s3b5YGDRpk0rO1Wq20YcMGqVOnToXq0VhF/RnI1cyZM6V169aZ/bm//fabNHDgQKl169ZSTEyM/vqECROkDRs2SJIkSampqdIzzzwjJScnF/r8kSNHpDFjxhR578DAQGnr1q2SJEnShQsXJF9fX0mj0ZT9lzBSt27dpHPnzlXY86lqUFV0oCIyh3r16mHq1KlYv349evfujbVr16JPnz4IDg7Wv8fV1RXh4eF4/vnn9b0L1tbWGDNmDKZPn46IiAhYWlqW+Jzt27djy5YtsLCwQK1atTBv3jw0adIEs2bNgp2dHRISEpCSkgJPT08sWbIE1apVM/o7pKamQhAE5OTkwNraGlZWVpg3bx7S0tKK/UzHjh2xYsWKQtf//PNPDB8+HEePHoWlpSUEQcBzzz2HjRs3IjMzEwkJCfjkk08wduxYo8v3b7Nnz0ZOTg6CgoIQGRmJNm3a4Pnnn8fly5exfPlyJCQkYPv27dBqtUhPT8e4cePw0ksvITIyEvv378eaNWswcuRItG3bFr/99huSk5PRsWNHLFiwALdu3UJgYCDOnDmDjz/+GElJSUhNTUVSUhJcXV2xbNkyuLi44Ny5c3j//feh1WrRsGFD3Lp1C7NmzcKzzz6rL+eBAwdw6NAh/PLLL7C2tkZaWhru37+PkJAQdO/eHf3798evv/6K9PR0vPbaa/jtt99w4cIFqFQqrF69Gq6urrh9+zY++OADJCcnQ6vVol+/fpg4cSIAYM6cOfD29saLL75YqI62bNmCt99+G2vWrClw/bPPPoP0eL/TW7duQaVSwcrKqtDnz5w5gwcPHmDo0KHIzc3F0KFD8dJLL+HSpUtIT0/HSy+9BABo2bIlvv76aygUigKfT0xMxKhRo+Dn54f4+HgIgoCpU6di+/btuH79Ory9vbFixQqj67t79+5YuXIlWrVqBQD6nw8ePIg7d+5g+vTpWLp0Kdzc3BAaGoorV65Aq9WiY8eOeOedd6BSqbBq1SocOHAAarUajo6OCAsLg4uLS6n+DlLVwyEnqjKaN2+OK1euAADi4uLwv//9r9B7atWqBXd3d5w7d05/bdKkSbC1tUV4eHiJ9z9+/DjWrVuHzZs3Y8+ePejfvz+mTJmib5zi4+Oxfv16REdHIykpqcAwgzEGDRqE6tWrw9/fH8OGDcPixYuRnJyM1q1bF/l+nU6HnTt3FmjA8zVp0gRNmzbFoUOHAAA///wz6tevD3d3d7Ru3RphYWFwdnY2qXz/FhYWBmtra+zevRtKpRJarRbdunXD/v374ebmhh07dmDt2rWIiopCeHg4li1bVuR9/v77b2zZsgV79uzBkSNHcPLkyULvOX36NFauXIl9+/bBxsYGERER0Ol0+L//+z+88cYb2Lt3L0aOHIlLly4V+mzPnj3RvXt3jB49GiNGjCj0ukajwTfffIM33ngDISEhGDVqFPbs2YM6deroh4JmzJiBwYMHIzIyEjt37sSxY8f0Q4ShoaFFhhkAWLFiRZFDehYWFlAqlRg5ciSGDx+OF154AY6OjoXep1Qq0b17d3z11VdYs2YNNm3ahIMHD+LPP/9EvXr1EBYWhiFDhmD48OFITU2FWq0udI/ExER07doVkZGRaNu2LUJDQ7FixQp8//33OH36NM6ePWtUfZdk2rRpcHFxwfLly9GmTRssWrQIXl5eiIyMRFRUFO7fv48NGzYgOTkZmzZtwq5duxAZGQk/P78C/39IZAh7aKjKUCgUsLa2Nuq9oijq/9vCwgLLli3DwIEDS5xTcvToUfTt2xdOTk4AgODgYISGhiIxMREA0LlzZ30PT7NmzZCenm5S+e3t7fHll1/i5s2b+PXXX3Hy5EmMHz8eL730EmbMmAEAiI6ORlxcHABAq9XCy8sLCxYsKPJ+L7zwAr799lv06dMHkZGRGDp0qEnlMZWvry8AoFq1avj888/x008/4a+//sLly5eRlZVV5Ge6desGCwsL2NnZoVGjRkhPT0f9+vULvKd9+/aws7MDkNcbkZ6erg+uXbt2BQB06NABTZs2NbnMvXr1AgA0aNAAtWrVQvPmzQEADRs2RHp6OrKysnDq1Cmkp6dj5cqVAICsrCxcvnwZffv2Nfl5/7ZlyxakpaVhzJgx2LVrFwYPHlzg9SlTpuj/29XVFcOGDcOBAwfg5+eH3377DWPHjsXs2bNx7tw5jBs3Dnv27IGrq2uBe6jVanTv3l3/nZ555hl9Xbq4uCA9Pb1QD0lR9W2Kw4cP4/z589i5cycAICcnR/8dmjdvjkGDBqFLly7o0qULOnbsaNK9qWpjoKEq4/z582jWrBkAoF27djh58iR69+4NALh37x4cHByQnp6Oa9euoXXr1hAEQf/ZOnXqYP78+Zg5cyYGDhxY5P3/HYLySZIEnU4HAAXClEKh0PfcGOuLL76Aj48P2rVrhwYNGmDIkCE4ffo0xo0bpw80ffv2RUhISKHP3r59G+PHj9f/vHbtWgQEBGDx4sW4du0aTp06hcWLFxtdlqLu99/G8r9sbW0BACkpKRg2bBiGDh0KHx8f9OnTBz/++GORnzGmzop6j1KpLPRepVJp+Iv9x7+HGIvq4RBFEZIkISIiAjY2NgCAtLS0IoeIjLVv3z74+/vDzs4OTk5O6NGjBy5evFgo0GzZsgXPP/886tatCyDv75pKpYKLiwuqV6+OHj16AABat26N+vXr4/Lly0UGmn8PRRX1Hf+rpD+Tf/93/mT1/xJFEStXroS7uzsA4OHDh1AoFLCwsMBXX32F8+fP4/jx41i0aBE6d+6Md955x2CZiAAOOVEV8eeff+Kzzz7TzwmZMGEC9u/frx82+O677xAYGIjJkydj+PDhqFOnTqF79OnTB126dMGmTZuKfEbnzp0RHR2tn9Oya9cuODg4oFGjRmXyHXJycvDhhx/iwYMH+mtXrlxBy5YtDX7W1dUVu3fv1v/P1dUVVlZW6NevH2bNmoVevXrpG2RjFHW/f1OpVBAEocgAEh8fDycnJ0yePBn+/v76MPPvAPmk3N3dYWlpiSNHjgAAzp07hytXrhSaRwLkBZ380GkqOzs7tG3bFhs2bACQ1zi/+OKLiI2NLXXZt23bhq+++gpA3kqm2NhYdOjQodD74uLisH79egDAgwcPsHPnTvTt2xft2rWDpaWlvl6vXbuGmzdv6nuXyouTk5N+JdOJEyeQmpqqf+3fdezv74+NGzdCkiTk5uZi0qRJ+Oqrr3D58mX0798f7u7umDBhAkaPHo3z58+Xa5np6cIeGnoq5U9IBfKGjKysrPDWW2/hueeeA5DX47J9+3aEh4fj888/h0qlgkqlQs2aNXH9+nVcvXq1yAZ+7ty5+iGd//Lz88Po0aMxatQoiKIIJycnrFmzBhYWZfPvhsmTJ0OhUGD48OFQKBQQRRHe3t746KOPSn3PIUOG4KuvvsL7779fJmXM5+zsjNatW6Nfv376JdH5/Pz8sHPnTvTp0wcKhQLt27eHk5MTbty4UWbPV6lU+Pjjj/Hee+9hxYoVaNy4MWrVqlXkkGOXLl1M6p36r+XLl2PBggUIDAxEbm4u+vfvjwEDBgAoeVJwcRYvXoyQkBAEBgYCAIYOHYqePXsWul9ISAhCQkLQr18/6HQ6jBgxAn5+fgDythZYuHAhPvzwQwDAokWLDPagPanp06fj/fffx/bt2+Hl5QUvLy/9az179sSMGTPw/vvvY86cOQgNDUVgYCC0Wi06deqE1157DWq1GgEBARg8eDBsbW1hbW2NuXPnlmuZ6emikEzt9yZ6yl2+fBlWVlZo0qRJRReFnsCSJUvw6quvolatWkhOTkZQUBAOHjyI6tWrV3TRiKgcsIeG6D/Ku2uezKNevXoYPXo0VCoVJEnCwoULGWaInmLsoSEiIqJKj5OCiYiIqNIze6CJi4vDCy+8gKCgIIwaNQpJSUkAoN8tNP9MnaI2wSIiIiIqitmHnLp3747PPvsMzZs3x86dOxEbG4vVq1fjo48+glarxYwZM3Do0CF88cUX2LZtm8H7iaKIzMzMQvspEBER0dNDkiRotVpUq1atyNWjZp0UnJubizfeeEM/6dLT01O/30J+MAGA7Oxso3d0zczM1O8KSkRERE+3Zs2awd7evtB1swYaS0tL/d4goijik08+0e9mOXbsWAwbNgz+/v7IzMzEl19+adQ983e2bNasmcGDA0sjPj4e3t7eZX7fpxXryzSsL9OwvkzD+jIe68o0FVFfubm5uHLlSrE7WpfbkFNMTAzCwsIKXHNzc8PGjRuRm5uLWbNmIT09HZ9//jnUajXefvtttGnTBq+88grOnDmDadOm4fvvvzd4GrFGo9HvTklERERPN29v7yKPFym3HpqAgAAEBAQUup6ZmYlJkybBwcEBq1ev1iet2NhYfPDBBwCAZ555BjVr1tSfqWOM4r7gk4qLi4OPj0+Z3/dpxfoyDevLNKwv07C+jMe6Mk1F1JehDgyzr3KaMWMGGjVqhI8++qjAEFHz5s1x8OBBAMBff/2FO3fucKdWIiIiMopZ59BcvHgRsbGx8PDwwKBBgwDkHVH/xRdf6M8v+eKLL2BpaYklS5YUOemHiIiI6L/MGmhatmyJhISEIl9r3LgxNm/ebM7iEBER0VOCOwUTERFRpcdAQ0RERJUeAw0RERFVegw0REREVOkx0BAREVGlx0BDRERElR4DDREREVV6DDRERERU6Zl1Yz0y3pmEO/jl3C0M7+mJWg42Rn9OqxNw/to9nL50GzXsLDGgsztsrAr/MedqBSiVFlBaKIq9V06uDgk37uPi9Xu4/0iD1wZ4w1KtLPS+uMu3ceRMEuq72EH7KBv1GmfCxdEWFv+5t0Yr4EzCHZy8kIKHmbn66yqlBUb0aY4GroV3hr6Xno31ey4gVysYXQfm1LC2PV7u06LQdwWA2FN/4/j55GI/a2GhQMs6OhR1GkpGVi7WRJ5HTq6uDEtb+T1If4CY309UdDEqDdaX8VhXpimpvlo2cUJwt6ZmLhEDjez8kfgAm767iLNXUwEA567eRegkPzg7Fh9qRFHCyYsp+DHuJs4k3EG2RoClygK5OhHf//wnRvRpgR7tG8JCAVz8Mw37fv0Lv/x+C4IooVYNazg72qJmDWtAygsduVoBGdla/JmUDkH85zD2Fo2d0M2nQYFnS5KEdbvjkXIvEzoh773bjhyEpVqJ+s52qO9ih3oudki88winL6UgWyPAzkZd4PvcSH6Iei52GBnQotB3O3YuGUfPJqFxnepQFJ+9KoROEHHiQgqcHW0R0LFxgdeu3ryPVdvPoKaDDexsij7qPuVeJm6nqjCwd+HX9v96Az+dSZTl965IWVkCcsWsii5GpcH6Mh7ryjQl1Zerk62ZS5OHgUYmHmVrsSbyHA7/lgh7W0uMC/KGW70aWPDlCcz+7GcsmuQHl//8JdEJIo6cScLOQ1dx83YGnKpbocsz9fGsV220buqMP2+l48s9F/DJjrPYe/QaREnCzduPUM1ahR7tG8LORo3U+9lIfZCNhBv3YWGhgJVaCSu1EnbWagR380DLJjXRvLET3vroJ+z/9UahQHPxzzQk3nmEN4a1RcdWdXHgp1OwcaiLm7cfIfFOBhL+vo+jvyehejVLdHmmPvxa10Urj1pQKf8Z7fy/5T/ij8QHRdbLH4kP4GBvhVVvPweFzFp2SZIw9/Nj2LD3Av7XwlXfk6YTRKzafhYO9tZY9Xa3YgPNth8S8PX+y0i5l4naNasVuO8PJ27Ay60mFk/xN8t3qSx4IrJpWF/GY12ZRo71xUAjAyn3MvHB+l+RfDcTQ55visHdmqLa40ZwwYROCFl7HLM/+xmhk/wAAFdvPsDVmw/wy7lbuJOWhUa17TF9hA/829SF8l9BoXkjJyx53R/HziVj2w+XUc1ajTeGPQP/tnVhbWnaH32fDo2w4buLuHk7o8DQ0L5f/4KttQr+berB2kqFBs5W8PFpXOCzhoa33OrVQNzl25AkqVBouZ6UDvd6NWQXZgBAoVDg/4a2xZRlP2L1rnOYO7Y9FAoFIn/8A38lP8ScMe2LDTMA0LN9Q2z74TIOnPy7QO/U+Wt3kXw3Ey/28jTH1yAieiow0FSwhBtpWPjlSWgFER+M74RWHrUKvN6soSMWTuyEeZ8fw4Swg8gfAVIpLdC8sSMmDGwF3xauRc7hAPIaXb82deHXpu4TlbO7b0NsibmEfb/+hXFBrQAADzNz8cvvt9CzfUNYFzFPJ19R827+zaO+Aw6dvom0hzmoWeOfoSiNVsDftzPwrFftJyp7eapdsxpe7tMcX+69gJ/P3kLjutWx7YcE+LWpiw7edUr8bC0HG3jUscbBk3/jpV6e+jC6/9cbqGajRqfWT/ZnRkRUlTDQVKBj527hw61xcKphjUWv+hU5KRbIa/DDpvjj4Mm/Uc+5GjwaOKBxnepQq0oOCmXJwd4KHbzr4NCpmxjVtyUs1Ur8GHcTWp2IPv+ZP2Iq9/o1AAB/3HxQIND8dSsdoijpX5erAZ3dcPRsEtZEnUNtp2qwtlRiwqBWRn22nXs1bD96D3GX76C9V208zMzFsXPJ6NOhEawMBEEiIvoHl21XkNT72Vi65TSa1KuB5VO7FBtm8jWuUx2vBXkjoFMTNG3gaNYwk69Ph8Z4lK3FsXO3IEkS9v/6F5o1dECTuk8WONzq1oBCAVxLSi9wPf9n9/oOT3T/8qZUWuD/hrbFoywtEv6+j1cHeMPR3tqozzarZw1Heyvs//UGAOBw3E3oBBG9OjQqzyITET11GGgqyI9xNyGIEqaP8EENO6uKLo5RWnnUQp2a1bDv1xu4+Gcabt5+hN4dGj/xfa2tVKjvYldoYvAfNx/A3tYSziYsW68oTerWwMTg1ujv1wTP/6+B4Q88prRQ4Pn/NcTpSym4l56N/SduoGmDJw+JRERVDQNNBZAkCbGn/oaXW80Cq1vkzsJCgV4dGuHC9XvY9P1F2Fip0KVtvTK5t3t9B1xLLNxD41FfnhOCi9KnY2NMCG5tcnl7PtsQogR8tvMc/k7JQG/2zhARmYyBpgIk3LiPW3cz8byv8f+Sl4vn/9cASgsFLv2Vhud86pc4GdgU7vUckPYwB/cf5gDI2yDw75SHsh9uKgt1a9mhtUctnLyYAmtLJTqXUUgkIqpKGGgqwMFTf8PKUvnEK48qgqO9tX71Tp8yGG7K5/F44m/+vJkbyRnQCRI8qkCgAYBez+b1ynRuWw+21sUv9SYioqJxlZOZabQCfj6bhI6t6lTahmt0/5Zo19wFbvXKbp5H/r3+SHwA3xau+vk0cl/hVFY6ta6DATfdEOjvVtFFISKqlBhozOxEfDIyc3To4duwootSarVrVivzuT+21mrUc66Ga4+DzLWkdFSzUVfYFtrmplYp9fv7EBGR6TjkZGaxp2+iloNNoQ30KG8ezR+PJwb/kfhAtjsEExGR/DDQmNG99GycTbiD7r4Nit3Ztypzr++Auw+ycS89G3/delhl5s8QEdGTY6Axo8NxiRAloHslXN1kDvnzZQ7HJUIniFVm/gwRET05Bhoz+jHuJlo0dkI9Z7uKLoosuT+eGLz/RN6uuVVhyTYREZUNBhozEUQJN29ncO5MCexsLVG7pi2S72bCxkqFOpVo00EiIqpYDDRm8vCRBqIEONlXjmMOKop7PQcAecu4Oc+IiIiMxUBjJmmPd8B1rG7coYVVVf68GU4IJiIiUzDQmMn9DA0AwImBpkT5QYYTgomIyBQMNGaSf0aRA4ecStS6qTOmDm0L/0p4LAQREVUc7hRsJmkZeYGGPTQlU1oo0PNZnjZNRESmYQ9NGdLqRORqhSJfe/BQg2o2aliqlWYuFRER0dOPgaYMrdp+BgvWnyjytbSMHDhyuImIiKhccMipjAiihFMXU6BUFp0R7z/UcLiJiIionLCHpoz8mZSOzBwdHmbmIidXV+j1+xk5cLRnoCEiIioPDDRl5Py1u/r/Tr2fXeA1SZKQ9lADx+occiIiIioPDDRl5Py1u8jf2Db1QcFAk5WjQ65WYA8NERFROWGgKQOCIOLC9Xto6+kCAEi9n1Xg9fv6JdvsoSEiIioPDDRl4PqtdGTl6PBcu/qwsFAUGnK6/zBvl2D20BAREZUPBpoycP6PewCANk2dUbOGNe78p4fmn3Oc2ENDRERUHhhoysD5a3dRz9kOTtWt4exgU2gOzX3uEkxERFSuGGieUP78mdYetQAALo62uFPEkJNaZYFqNuqKKCIREdFTz+yBJi4uDi+88AKCgoIwatQoJCUlAQD++usvvPzyywgMDMTIkSPx559/mrtopXItKR3ZGh1auecFGmdHG9x7kA1BlPTvyd8lWKFQVFQxiYiInmpmDzQzZszAwoULsXv3bgQGBmLhwoUAgNmzZyM4OBh79+7F22+/jTfffNPcRSuV83/k7T/j7V4TAODsaAtBlPSnawN5J207criJiIio3Jg10OTm5uKNN95A8+bNAQCenp5ITk4GAFy6dAl9+vQBALRt2xZ37tzBzZs3zVm8Ujl/7S4auNrpA4uzgw2Agpvr3c/Q8BwnIiKicmTWs5wsLS0RFBQEABBFEZ988gl69OgBAGjZsiW+//57DBkyBMePH8eDBw+QmpqKBg0aGHXv+Pj4cit3XFxckdcFUcL5P1LRuomt/j2p6VoAwInfLiArzTbvWlomXOzFYu/ztKkq37OssL5Mw/oyDevLeKwr08itvsot0MTExCAsLKzANTc3N2zcuBG5ubmYNWsWdDodJkyYAABYvHgxFixYgC1btqBLly5o3rw51GrjJ9F6e3vDyqrse0Hi4uLg4+NT5GsJN9KQq0vC8x1bwKdNPQBAtkaHz77/HnaOteHj0xRanYDsrxPh6d4APj6eZV4+uSmpvqgw1pdpWF+mYX0Zj3VlmoqoL41GU2LnRbkFmoCAAAQEBBS6npmZiUmTJsHBwQGrV6/WhxadTodPP/0UlpaW0Gq12L59O+rXr19exSsT56/l7T/j7VZLf83GSgV7W7V+L5r7Gfmb6nHIiYiIqLxUyKTgRo0a4aOPPoKlpaX+enh4OGJjYwEAO3fuRKtWreDo6Gju4pkk+W4mHOyt4PCfsOLsYKufQ3Nfv6keJwUTERGVF7POobl48SJiY2Ph4eGBQYMGAQBcXFzwxRdfYPr06Zg5cyY++eQTuLq6FhqukqNsjQ62VoWr0NnRBrfT8npo0h4fe+DEYw+IiIjKjVkDTcuWLZGQkFDka40aNUJERIQ5i/PEsjU62FgXHWjOX8tbzv0gg8ceEBERlTfuFPwEsjU62BTRQ+PiaIusHB0ys7VIe6iBQgE42DHQEBERlRcGmieQnVN0oHF2zNuL5s79LNzPyEGNalZQKlnVRERE5YWt7BMoqYcGAFIfZOP+Q02hScNERERUthhonkBxgUa/W3BaFtIycnjKNhERUTljoHkCWRodbK0Lb/5Xw84KapXF4x6aHE4IJiIiKmcMNKUkCCJytUKRPTQWFgrUcrBBSloWHmRo4Mgl20REROWKgaaUsjU6ACgy0ACAi6MNrielQxAl9tAQERGVMwaaUsoyEGicHWyRfDcTADiHhoiIqJwx0JRSfg9NUTsFA3k9NPk45ERERFS+GGhKST/kVMROwcA/e9EA3CWYiIiovDHQlFJ2joEhp8d70QDsoSEiIipvDDSlZGhScH4PjY2Vstj3EBERUdlgoCklg4Hm8eZ67J0hIiIqfww0pWQo0KhVSjjaW8GRK5yIiIjKHcdCSkm/yqmYScEA4N+2HmrVYKAhIiIqbww0pZSt0UFpoYBaVXwn1/iBrcxYIiIioqqLQ06llJWTdzClQqGo6KIQERFVeQw0pZSt0RW7Bw0RERGZFwNNKWVrdFyOTUREJBMMNKWUncNAQ0REJBcMNKXEHhoiIiL5YKAppSwGGiIiItlgoCkl9tAQERHJBwNNKWVrdCVuqkdERETmw0BTCpIksYeGiIhIRhhoSiFXJ0IUJQYaIiIimWCgKYWsHC0AwJaBhoiISBYYaEpBf9I259AQERHJAgNNKWTnPA407KEhIiKSBQaaUtD30DDQEBERyQIDTSkw0BAREckLA00pMNAQERHJCwNNKfwTaNQVXBIiIiICGGhKJT/QcKdgIiIieWCgKYX8VU7WHHIiIiKSBQaaUsjS6GBlqYTSQlHRRSEiIiIw0JQKz3EiIiKSFwaaUsjOYaAhIiKSEwaaUshiDw0REZGsMNCUAoeciIiI5IWBphQYaIiIiOTF7IHm9OnTCA4ORmBgICZOnIj09HQAwMOHDzF+/HgEBARgxIgRSE1NNXfRjJat0cGWgYaIiEg2zB5oZs+ejaVLl2Lv3r3w8PDA+vXrAQAfffQRfH19ERMTgyFDhiA0NNTcRTNatkYHG26qR0REJBtmDzTR0dHw8PCAVqvF7du3Ub16dQDA4cOHERgYCADo378/jhw5Aq1Wa+7iGYVDTkRERPJi9kCjVquRkJCArl274sSJE+jXrx8A4M6dO3B2dgYAqFQq2NnZIS0tzdzFM0gQJWhyBQ45ERERyYhCkiSpPG4cExODsLCwAtfc3NywceNG/c8RERGIiopCREQEvL29cfbsWahUeUGhc+fOiIyM1Iec4mg0GsTHx5d5+YuTkyti8c5b6PVMDXRqYW+25xIRERHg7e0NKyurQtfLrZshICAAAQEBBa5pNBocPHgQPXr0AAAMGDAAS5YsAQC4uLjg7t27qF27NnQ6HTIzM+Hg4GD084r7gk8qLi4OPj4++p9T72cDuIVmHo3h49O4zJ9X2f23vqhkrC/TsL5Mw/oyHuvKNBVRX4Y6MMw65KRSqTB//nx9gWJiYtCuXTsAQNeuXREVFQUgb56Nr68v1Gq1OYtnlGxN3rwezqEhIiKSD7O2ykqlEuHh4QgJCYEgCHB1ddWvZnrjjTcwa9Ys9OvXD/b29li+fLk5i2a0bE3eSdsMNERERPJh9lbZ19cXkZGRha47ODjg888/N3dxTMZAQ0REJD/cKdhEDDRERETyw0BjIn2g4cZ6REREssFAY6LsnLxAY2slvwnLREREVRUDjYmy2ENDREQkOww0JsrW6GBhoYClilVHREQkF2yVTZSdk3eOk0KhqOiiEBER0WMMNCbK4sGUREREssNAYyKetE1ERCQ/DDQmytboeNI2ERGRzDDQmIg9NERERPLDQGOibI2OS7aJiIhkhoHGROyhISIikh8GGhNl53AODRERkdww0JhAkiQOOREREckQA40JtDoRgihxyImIiEhmGGhMkPX4YEoGGiIiInlhoDFBtoaBhoiISI4YaEzAQENERCRPDDQmYKAhIiKSJwYaE+gDDVc5ERERyQoDjQmyOSmYiIhIlhhoTJD1uIfG1kpdwSUhIiKif2OgMQGHnIiIiOSJgcYEWp0AALBUsdqIiIjkhC2zCXSCBABQKlltREREcsKW2QSCKAIALBQVXBAiIiIqgIHGBIIgQaVUQKFgoiEiIpITBhoT6ASRw01EREQyVOxynaioqBI/OHDgwDIuivyJogQlx5uIiIhkp9hAs2/fPgBAamoqrl+/jg4dOkClUuHEiRNo0aJFlQw0OkGE0oI9NERERHJTbKD5/PPPAQDjx49HeHg4GjZsCAC4desW5s2bZ57SyYwg5s2hISIiInkx2N2QnJysDzMAULduXaSkpJRroeRKECTOoSEiIpIhg1veOjs7Y9WqVRg0aBAAYPv27WjQoEG5F0yOdKLIOTREREQyZLC7YfHixbhy5QqCgoIwaNAgJCUlYdGiReYom+zkL9smIiIieTHYQ7NlyxZ88skn5iiL7HHZNhERkTwZbJ0PHz5shmJUDly2TUREJE8Ge2jq16+PsWPHol27dqhWrZr++pgxY8q1YHLEHhoiIiJ5MhhoHBwcAABJSUnlXRbZEwQJKvbQEBERyY7BQBMWFmaOclQKgshl20RERHJkMNCcOXMGa9euRVZWFiRJgiiKSExMrJJza3SCCLWKgYaIiEhuDLbOc+fOxTPPPINHjx4hMDAQdnZ26NWrlznKJjuCKELFHhoiIiLZMdhDo1AoMH78eNy/fx9ubm4IDAzE4MGDzVE22dEJEpTch4aIiEh2DHY35K9satiwIa5evQpra2tYPMEBjadPn0ZwcDACAwMxceJEpKenF3h9x44dmDVrVqnvX564bJuIiEieDCaTVq1a4c0330SHDh3w5ZdfYvHixVCpDHbsFGv27NlYunQp9u7dCw8PD6xfvx4AoNFosHz5clnvQsxl20RERPJk1Bya0aNHo0mTJnj33XchiiI+/PDDUj8wOjoaHh4e0Gq1uH37NqpXrw4AOHXqFERRxIwZM0p97/KWt2ybgYaIiEhuDHa1DB06FL1790bNmjXx3HPP4bnnnnuiB6rVaiQkJGDMmDFQqVR46623AAD+/v7w9/dHZGTkE92/PAmiyDk0REREMqSQJEkq6Q1xcXE4dOgQDh06BBsbG/Tu3Rs9e/aEm5tbiTeOiYkptIeNm5sbNm7cqP85IiICUVFRiIiI0F+LjIzEyZMnsXjxYqO+gEajQXx8vFHvfVIffnsLHnWtEfSsk1meR0RERAV5e3vDysqq0HWDgebfoqOjsWzZMqSkpODSpUsmF0Kj0eDo0aPo0aMHACArKwt+fn44c+aM/j2lDTTFfcEnFRcXBx8fHwDAy+/FoFOrupj8Qpsyf87T4t/1RYaxvkzD+jIN68t4rCvTVER9GWrvDQ45ffvtt/jll19w4sQJ1KtXD4MGDYK/v3+pCqNSqTB//nzUrl0b3t7eiImJQbt27Up1r4ogcNk2ERGRLBkMNAsXLoStrS0mTJiA3r17w9nZudQPUyqVCA8PR0hICARBgKurK0JDQ0t9P3MTRBFKTgomIiKSHYOB5sSJE4iLi8PRo0cxYcIEiKKIjh07YubMmaV6oK+vb4kTf4ODgxEcHFyqe5c3nSBBxR4aIiIi2THY3aBSqfDss8+id+/e6N69O3JycvDTTz+Zo2yyI3AfGiIiIlky2EPzzjvv4Oeff0adOnXQs2dPfPrpp3B3dzdH2WRFFCWIErhTMBERkQwZDDReXl6YNm0a6tSpY47yyJYg5i0G46RgIiIi+TE4fjJ48GCsXbsWo0aNwoMHDxASEoLMzExzlE1WBEEEAO4UTEREJEMGW+fQ0FBUr14d9+7dg5WVFR49eoSQkBBzlE1W2ENDREQkXwYDzaVLlzBt2jSoVCrY2Nhg+fLlpdpUr7LTPe6h4bJtIiIi+THYOlv8pwEXBKHQtaogv4eGy7aJiIjkx+Ck4P/9739YtmwZcnJycPToUWzduhXt27c3R9lkRRDyh5yqXpgjIiKSO4Ot8/Tp02Frawt7e3uEh4fD09Oz1JvqVWaCmD/kxB4aIiIiuTHYQ6NWqzFlyhRMmTJFf+2PP/6Ah4dHuRZMbvRzaNhDQ0REJDvFts6JiYl4++23sWDBAmRnZwMAMjMzERYWhoEDB5qrfLKRP+TEOTRERETyU2ygeffdd+Ho6IjU1FSsWbMG586dQ79+/fDLL79g3bp15iyjLOiXbXPIiYiISHaKHXJKSUnB5s2bkZOTg+DgYHzzzTcYPXo0xo4dC5XK4EjVU4dDTkRERPJVbDKxtbUFAFhbWyM9PR1Lly6Fv7+/2QomN/ohpyq4ZJ2IiEjujGqdnZycqnSYAbjKiYiISM6KDTQKxT8Nd1UcYvqvf/ahYaAhIiKSm2KTSkJCAtq1awcAyMnJ0f+3JElQKBT47bffzFNCmdA97qFRcQ4NERGR7BQbaA4cOGDOcsgee2iIiIjkq9hAU69ePXOWQ/b+mUPDHhoiIiK5YetsJB17aIiIiGSLgcZIgsA5NERERHLF1tlI3CmYiIhIvgwGmtTUVIwfPx69e/fG3bt38eqrr+LOnTvmKJus6IecOIeGiIhIdgy2zvPnz0ePHj1gZWWFGjVqoHnz5pg7d645yiYrgn7ZNntoiIiI5MZgoElKSsLQoUNhYWEBtVqNGTNmIDk52Rxlk5V/lm2zh4aIiEhuDLbOCoUC4uPeCQB49OhRgZ+rCh59QEREJF8GzzTo1asXpk+fjoyMDERERGDHjh0ICAgwR9lkhcu2iYiI5MtgoJk4cSKioqIgiiKOHTuGYcOGYciQIeYom6xw2TYREZF8GXXq5MCBAzFw4MByLoq8cdk2ERGRfBkMNF5eXoXmzFhbW6NZs2ZYtGgR3N3dy61wcqITRFhYKAqcQk5ERETyYDDQvPLKK6hWrRpGjhwJCwsL7NixA9evX0fXrl3x/vvvY8uWLeYoZ4UTBAkq9s4QERHJksEJISdOnMDrr7+OGjVqwN7eHmPHjsXly5fRs2dPPHz40BxllAVBlDghmIiISKYMBprs7OwCOwPfuXMHGo0GACAIQvmVTGYEQeQuwURERDJlcMhp3LhxGDRoEPz9/SGKIo4fP47Zs2fjk08+Qbt27cxRRlnQiRJXOBEREcmUwUATHByMNm3a4OjRo1CpVJgyZQoaN26MxMRE1K5d2xxllAVBEDnkREREJFNGLdvWaDTw9vaGJElISUnByZMnMXTo0PIum6wIosQl20RERDJlMNDMmTMHhw4dgkajgYuLC/7++2/4+PhUuUCjE0Se40RERCRTBlvo48ePIzY2Fj179sTatWuxYcMGWFtbm6NssiIIEk/aJiIikimDgcbZ2Rm2trZwc3PDlStX8OyzzyIlJcUcZZMVQeQqJyIiIrky2EKr1WqcOnUK7u7uOHLkCDIyMpCVlWWOssmKTuA+NERERHJlMNDMmDEDERER6Nq1Ky5fvowOHTpgwIAB5iibrAiCCBV7aIiIiGTJ4KTg+Ph4fPjhhwCAb775BhkZGbC3ty/3gsmNIEqw4ConIiIiWTLY5bBt27YCPz9pmDl9+jSCg4MRGBiIiRMnIj09HQBw7do1jBgxAkFBQRg2bBguXbr0RM8pawI31iMiIpItgz00TZo0wdy5c+Hr6wtbW1v99V69epXqgbNnz8bq1avh4eGB5cuXY/369Xjrrbcwd+5cTJgwAc899xyOHz+OmTNnYs+ePaV6RnnQCSJsrIzatoeIiIjMzGAL/eDBAzx48AA3btzQX1MoFKUONNHR0VCr1dBqtbh9+zY8PT0BAEOGDEHnzp0BAJ6enkhOTi7V/cuLIIjsoSEiIpIphSRJkrkfmpCQgDFjxkClUmH79u2oU6dOgdfff/99aDQahIWFGbyXRqNBfHx8eRVVb3X0bThUU+LFrrXK/VlERERUNG9vb1hZWRW6brCHJjU1FXPmzMGNGzfw9ddf45133sHixYvh7Oxc4udiYmIKBRI3Nzds3LgRnp6eOHbsGCIiIjBt2jREREQAACRJwtKlS/H7779j8+bNpny/Yr/gk4qLi4OPjw8sYw+hZk07+Pj4lPkznib59UXGYX2ZhvVlGtaX8VhXpqmI+jLUgWFwDGX+/Pno0aMHrKysUL16dTRv3hxz5swx+OCAgAAcOXKkwP/WrFmDgwcP6t8zYMAAJCQkAAB0Oh2mT5+O8+fPY/PmzbJbScVl20RERPJlsIVOSkrC0KFDYWFhAbVajRkzZpR6fotKpcL8+fP1CSsmJgbt2rUDACxZsgSPHj3Cl19+KbswAzxets2N9YiIiGTJ4JCTQqGAKIr6nx89elTgZ1MolUqEh4cjJCQEgiDA1dUVoaGhSEtLw9atW1G/fn0MGTJE//7du3eX6jnlgT00RERE8mUw0PTq1QvTp09HRkYGIiIisGPHDgQEBJT6gb6+voiMjCx0/eLFi6W+pznoRB59QEREJFcGA83EiRMRFRUFURRx7NgxDBs2rEAvSlWRd9o2e2iIiIjkyGCgiYiIQP/+/TFw4EAzFEe+8k7bZg8NERGRHBnscjhx4gR69OiBd999F2fPnjVDkeQp77Rt9tAQERHJkcEemvDwcKSnp+O7777DwoULkZOTgyFDhmDUqFHmKJ9s5O0UzB4aIiIiOTKqy6FGjRoYNmwYJkyYAFtbW3zxxRflXS5ZkSSJp20TERHJmMEemosXL2LXrl3Yt28fWrZsiXHjxqF79+7mKJtsiGLe6RCcFExERCRPBlvoyZMnw9HRETt27MDq1auh0WgwfPhwc5RNNnSPAw0nBRMREcmTwR6aQ4cOISMjA9u3b8fWrVuRlZWFl19+2Rxlkw1ByNtIUMmN9YiIiGSpxEBz/fp1bN68Gbt370a9evWQk5ODQ4cOyfJogvIk6Iec2ENDREQkR8V2OYwfPx4vv/wyVCoVNm/ejO+++w7VqlWrcmEGAHT5PTScQ0NERCRLxbbQFy9ehJeXF5o2bYpGjRoByDvXqSoS2UNDREQka8UGmsOHD2PQoEH47rvv4O/vj6lTp0Kj0ZizbLKhEzgpmIiISM6KDTQqlQp9+/bFli1bEBkZCRcXF2g0GvTq1Qvbtm0zZxkrnMAhJyIiIlkzqoX28PDA3LlzceTIEbz66qv45ptvyrtcspI/h0bFVU5ERESyZFILbWNjg2HDhuHbb78tr/LIUv4qJwvOoSEiIpIldjkYQXg8h0bFOTRERESyxEBjBJ3IOTRERERyxhbaCAJXOREREckaA40RhMc9NDyckoiISJ7YQhtBvw8NJwUTERHJEgONEf7ZKZjVRUREJEdsoY2Qvw+NBefQEBERyRIDjRH0y7bZQ0NERCRLbKGNoD9tmz00REREssRAY4T8nYI5KZiIiEieGGiMIPAsJyIiIlljC20EHXtoiIiIZI2BxgiiwI31iIiI5IwttBH0PTScFExERCRLDDRGyJ9Dw8MpiYiI5IkttBF0+n1o2ENDREQkRww0Rshftm3BVU5ERESyxBbaCIIgQqHgHBoiIiK5YqAxgk4QoWTvDBERkWyxlTaCIErcg4aIiEjGGGiMIIgSVBxuIiIiki0GGiPoBJFLtomIiGSMrbQRRFHikm0iIiIZY6Axgk4QuWSbiIhIxthKG0EQ2ENDREQkZww0RuCybSIiInkzeyt9+vRpBAcHIzAwEBMnTkR6ejoA4I8//sDw4cMxYMAAjBw5EklJSeYuWrG4bJuIiEjezB5oZs+ejaVLl2Lv3r3w8PDA+vXrAQDz58/H5MmTsWfPHvTt2xcrVqwwd9GKJQgSVOyhISIiki2VuR8YHR0NtVoNrVaL27dvw9PTEwCwYcMGqFQqiKKIW7duoXr16uYuWrF0osgeGiIiIhkze6BRq9VISEjAmDFjoFKp8NZbb+UVRKXCw4cP0bdvX+Tk5GDLli3mLlqxREHiOU5EREQyppAkSSqPG8fExCAsLKzANTc3N2zcuFH/c0REBKKiohAREVHgfUeOHEFISAhiY2OhVCpLfI5Go0F8fHyZlbsoGw7eAQCM6eFSrs8hIiKiknl7e8PKyqrQ9XLroQkICEBAQECBaxqNBgcPHkSPHj0AAAMGDMCSJUsA5A1FBQQEQKFQoEuXLsjJyUF6ejqcnJyMel5xX/BJxcXFwdbWDpZqC/j4+JT5/Z82cXFxrCcTsL5Mw/oyDevLeKwr01REfRnqwDDrTFeVSoX58+frCxQTE4N27doBAL788kscOHAAAPDrr7/C0dHR6DBT3gSRRx8QERHJmVnn0CiVSoSHhyMkJASCIMDV1RWhoaEAgMWLF2PevHn49NNPYW9vj1WrVpmzaCXScQ4NERGRrJl9UrCvry8iIyMLXffw8MC2bdvMXRyjCIIIFXtoiIiIZIuttBHYQ0NERCRvDDRGEEWJRx8QERHJGFtpI3BjPSIiInljoDEC59AQERHJG1tpI/BwSiIiInljoDECJwUTERHJGwONETjkREREJG9spY3AHhoiIiJ5Y6AxgsijD4iIiGSNrbQBoiRBlAAVe2iIiIhki4HGAFHM+7/soSEiIpIvttIGiJIEAJxDQ0REJGMMNAYI7KEhIiKSPbbSBohiXg+NihvrERERyRYDjQGP8wx7aIiIiGSMrbQBgsg5NERERHLHQGNA/ionDjkRERHJFwONAf/00LCqiIiI5IqttAH/zKFhDw0REZFcMdAYILKHhoiISPbYShsgcA4NERGR7DHQGPDPTsGsKiIiIrliK23AP2c5sYeGiIhIrhhoDBCk/J2CWVVERERyxVbaAPbQEBERyR8DjQEidwomIiKSPQYaA4TH+9BwyImIiEi+2EobwB4aIiIi+WOgMeCfOTSsKiIiIrliK22AILGHhoiISO4YaAzIH3LiHBoiIiL5YittAA+nJCIikj8GGgMEHk5JREQke2ylDRB5OCUREZHsMdAYoO+h4RwaIiIi2WIrbYB+Dg1XOREREckWA40B3FiPiIhI/hhoDBDEvDCjUDDQEBERyRUDjQGiJLF3hoiISOYYaAwQRU4IJiIikju21AYIosQl20RERDLHQGOAKLGHhoiISO7M3lKfPn0awcHBCAwMxMSJE5Genl7g9ZSUFLRv3x6JiYnmLlqRRJFzaIiIiOTO7IFm9uzZWLp0Kfbu3QsPDw+sX79e/5ooipgzZw60Wq25i1UsgXNoiIiIZM/sLXV0dDQ8PDyg1Wpx+/ZtVK9eXf/aunXr0KlTJzg6Opq7WMUSJQkq9tAQERHJmkKSJMncD01ISMCYMWOgUqmwfft21KlTB/Hx8VixYgXWrVuHHj16YPPmzahfv77Be2k0GsTHx5dbWb85eg930rV4vX/tcnsGERERGcfb2xtWVlaFrqvK64ExMTEICwsrcM3NzQ0bN26Ep6cnjh07hoiICEybNg0bNmzA/PnzsXLlSliU8lTr4r7gk9p2ZD/sqtnCx8enzO/9NIqLi2NdmYD1ZRrWl2lYX8ZjXZmmIurLUAdGuQWagIAABAQEFCrMwYMH0aNHDwDAgAEDsGTJEpw+fRr37t3DpEmTAAB37tzB+PHj8cknn8DNza28imgUUeRJ20RERHJXboGmyIepVJg/fz5q164Nb29vxMTEoF27dujcuTMOHTqkf1/37t2xdu1ao4acypsoSlCpOCmYiIhIzswaaJRKJcLDwxESEgJBEODq6orQ0FBzFsFkggRYsYeGiIhI1swaaADA19cXkZGRJb7n3701FU0UJai4bJuIiEjW2FIbID4+bZuIiIjki4HGAEGSuLEeERGRzLGlNoA9NERERPLHQGOAwDk0REREsseW2gBRYg8NERGR3DHQGCCKEpRctk1ERCRrDDQGCCI45ERERCRzbKkNELnKiYiISPbYUhvAVU5ERETyx0BjgMA5NERERLLHQGOAKAEqC1YTERGRnLGlNoCrnIiIiOSPgaYEkiQ93oeG1URERCRnbKlLIIgSAEDFHhoiIiJZY6ApQX6gseAqJyIiIlljoCmBIIgAuLEeERGR3LGlLoFOyOuh4aRgIiIieWOgKYEgsoeGiIioMmBLXQIhv4eGc2iIiIhkjYGmBLrHc2i4bJuIiEje2FKXgMu2iYiIKgcGmhII7KEhIiKqFNhSlyC/h4arnIiIiOSNgaYEOu5DQ0REVCmwpS4BdwomIiKqHBhoSpC/bJuTgomIiOSNgaYE+mXbHHIiIiKSNbbUJdAv2+YqJyIiIlljS10C/bJtDjkRERHJGgNNCXQ8+oCIiKhSYKApAQ+nJCIiqhzYUpegRWMnPONmi7rO1Sq6KERERFQCBpoS1Kxhg6AOTlCrlBVdFCIiIioBAw0RERFVegw0REREVOkx0BAREVGlx0BDRERElR4DDREREVV6DDRERERU6THQEBERUaXHQENERESVnsrcDzx9+jQWLVoErVaLevXqYcmSJahRowZOnjyJ//u//0Pt2rUBAC1btkRYWJi5i0dERESVkNkDzezZs7F69Wp4eHhg+fLlWL9+Pd566y3Ex8dj7NixmDBhgrmLRERERJWc2YecoqOj4eHhAa1Wi9u3b6N69eoAgPPnz+Pnn39GYGAgJk6ciOTkZHMXjYiIiCopswcatVqNhIQEdO3aFSdOnEC/fv0AAPb29hg5ciT27t2Lrl27Ytq0aeYuGhEREVVSCkmSpPK4cUxMTKE5MG5ubti4caP+54iICERFRSEiIqLQ5319ffHjjz/C3t6+xOdoNBrEx8eXSZmJiIhI3ry9vWFlZVXoerkFmqJoNBocPXoUPXr0AABkZWXBz88PcXFxWLNmDcaPHw+lMu9ka19fXxw5cgS2trYl3jMnJwcXLlxAs2bNYGlpWeZljo+Ph7e3d5nf92nF+jIN68s0rC/TsL6Mx7oyTUXUV25uLq5cuQIvLy9YW1sXet2sk4JVKhXmz5+P2rVrw9vbGzExMWjXrh0sLCxw4MABNGrUCH379kVUVBTatGljMMwAgFarBQBcuXKl3MrNHiDTsL5Mw/oyDevLNKwv47GuTFNR9aXVaosMNGbtoQH+WbYtCAJcXV3xwQcfoHbt2rh69SrmzZuHjIwMODk5YenSpahTp47B+4miiMzMTKjVaigUCjN8AyIiIjI3SZKg1WpRrVo1WFgUngJs9kBDREREVNa4UzARERFVegw0REREVOkx0BAREVGlx0BDRERElR4DDREREVV6DDRERERU6THQEBERUaXHQPPY3r170bdvX/Tq1Qtbt24t9PqlS5cQHByM3r17Y86cOdDpdBVQSvkwVF8HDx5EUFAQBgwYgMmTJyM9Pb0CSikfhuor3+HDh9G9e3czlkyeDNXX9evXMXLkSAwYMACvvvpqlf77ZaiuLly4gMGDB2PAgAGYMGECHj58WAGllJdHjx6hf//+SExMLPQaf9cXVlJ9yep3vURSSkqK1K1bN+n+/ftSZmamFBgYKF29erXAe/r16yedOXNGkiRJmj17trR169YKKKk8GKqvjIwMyc/PT0pJSZEkSZI++ugjacGCBRVV3ApnzN8vSZKk1NRUqU+fPlK3bt0qoJTyYai+RFGUevXqJf3000+SJEnSsmXLpKVLl1ZUcSuUMX+3XnzxRenw4cOSJElSWFiYtGLFioooqmycPXtW6t+/v+Tl5SXdvHmz0Ov8XV9QSfUlt9/17KEBcOzYMXTo0AEODg6wtbVF7969sW/fPv3rSUlJyMnJQdu2bQEAwcHBBV6vagzVl1arxXvvvQdXV1cAgKenJ5KTkyuquBXOUH3lmzt3Ll5//fUKKKG8GKqvCxcuwNbWFl26dAEATJw4ESNGjKio4lYoY/5u5R8PAwDZ2dlFnoFTlXzzzTd477334OLiUug1/q4vrKT6ktvvegYaAHfu3IGzs7P+ZxcXF9y+fbvY152dnQu8XtUYqi9HR0f07NkTQN5p6GvXrtWfsF4VGaovANi8eTNatmyJNm3amLt4smOovv7++2/UqlUL7777LgYNGoT33nvPqINsn0bG/N2aNWsW5s6dC39/fxw7dgzDhw83dzFlJTQ0FL6+vkW+xt/1hZVUX3L7Xc9Ag7x/wfz7YEtJkgr8bOj1qsbY+sjIyMD48ePRvHlzDBo0yJxFlBVD9XXlyhX88MMPmDx5ckUUT3YM1ZdOp8PJkyfx4osv4ttvv0WDBg2wePHiiihqhTNUVzk5OZgzZw42btyIn3/+GS+99BJmzpxZEUWtFPi7vnTk8ruegQZA7dq1kZqaqv85NTW1QPfaf1+/e/dukd1vVYWh+gLy/qXz0ksvwdPTE6GhoeYuoqwYqq99+/YhNTUVgwcPxvjx4/V1V1UZqi9nZ2c0atQIrVq1AgD0798f586dM3s55cBQXV25cgVWVlZo3bo1AGDYsGE4efKk2ctZWfB3venk9LuegQZAp06dcPz4caSlpSE7Oxs//PCDfnweAOrVqwcrKyvExcUBAHbv3l3g9arGUH0JgoCJEyciICAAc+bMqfL/wjFUX1OnTsX+/fuxe/durF27Fi4uLvj6668rsMQVy1B9PfPMM0hLS8Ply5cBAIcOHYKXl1dFFbdCGaqrRo0aISUlBdevXwcAxMbG6oMgFcbf9aaR2+96VYU+XSZcXV0xbdo0vPLKK9BqtXjhhRfQunVrjBs3DlOnTkWrVq2wfPlyzJ07F48ePYKXlxdeeeWVii52hTFUXykpKbh48SIEQcD+/fsBAN7e3hWe3iuKMX+/6B/G1Nenn36KuXPnIjs7G7Vr18bSpUsrutgVwpi6CgsLw5tvvglJklCzZk0sWrSooostO/xdbxq5/q5XSJIkVciTiYiIiMoIh5yIiIio0mOgISIiokqPgYaIiIgqPQYaIiIiqvQYaIiIiMgsSjro8t9KcwAtAw1RJebp6YnAwEAEBQUV+J+hXxbFWblyJaKiosq2kOUkIyOjyCW1x44d09eDn58fOnTooP85Ojq6XMs0btw4/PHHHwCAsWPHIi0trdB1oqrq999/x4svvoi//vqrxPdJkoRJkyZh3Lhx2LNnD1q0aIG1a9cavD+XbRNVYp6enjh+/DicnJwquihml5iYiMDAQJw5c6bY93z88ce4f/8+QkJCzFiyPFX5z4aoKHPmzMGgQYPwzjvvYPPmzahfvz6ioqKwadMmiKIILy8vvPfee7h69SrmzZuHb7/9FkBer87Dhw9Rt27dEu/PjfWInlInTpxAeHg4GjRogKtXr0Kn02H+/Plo1qwZunbtiv379+sP4hsyZAhef/11xMTEoGnTpnj11Vfh7e2N559/HpcvX8by5cuh0WiwdOlSZGdnQ61W480330SXLl0QGRmJAwcOwMLCAjdu3IC1tTWWLFkCd3d3jBw5El5eXjh79izS0tIwdOhQ3L17FydPnkR2djY++ugjeHp6IiMjA6Ghobhy5Qq0Wi06duyId955ByqVCq1atcL48ePxyy+/4M6dO3jttdfw0ksvYfbs2cjJyUFQUBAiIyOhVCoN1kliYiJGjBgBd3d3JCUlYcuWLYiMjERsbCxycnKQnZ2NmTNnomfPnvj444+RlJSE1NRUJCUlwdXVFcuWLdPv5BwREQG1Wg0rKyt88MEH8PDwQPfu3bFy5Ur9Ts+jRo3C2rVrMWLECKxcuRKtWrXC9u3bsWXLFlhYWKBWrVqYN28emjRpglmzZsHOzg4JCQlISUmBp6cnlixZgmrVqmHVqlU4cOAA1Go1HB0dERYWxi35qdL574Z7V69exTfffIOIiAhYWVnhww8/xPr169G4cWP9AbSXLl2Cm5sb5s2bZ/D+HHIiquRGjRpVYLhpypQp+tfOnTuHsWPHIioqCsHBwQgPD4e9vT169uyJPXv2AACuXbuGu3fvonPnzgXuq9Vq0a1bN+zfvx/169fH1KlTMWfOHOzduxdLlizBjBkzcPPmTQDAqVOnMG/ePHz33Xdo06ZNge7hpKQkREREYNmyZVi2bBnat2+PyMhIdO7cGV999RUAYNGiRfDy8kJkZCSioqJw//59bNiwAQCQm5sLR0dHREREYNWqVQgLC4NGo0FYWBisra2xe/duo8JMvpSUFEyePBn79++HVqvFsWPHsGXLFuzduxfTpk3DqlWr9O89ffo0Vq5ciX379sHGxgYREREQBAGLFi3CunXrsGvXLgwdOlS/VX6+sLAwAMCmTZtQp04d/fXjx49j3bp12Lx5M/bs2YP+/ftjypQpyO8oj4+Px/r16xEdHY2kpCTs27cPycnJ2LRpE3bt2oXIyEj4+flV2bOr6Oly4sQJ3LhxA0OHDkVQUBBiY2Nx/fr1Uh9Ayx4aokpu06ZNxQ5r1K1bFy1atAAAtGzZUt+FO2TIEMyfPx+vvvoqdu3ahcGDB8PCovC/b3x9fQHkBaOGDRuiTZs2AICmTZuiXbt2OHnyJBQKBby8vFC7dm39cw4cOKC/R8+ePQEADRo0AAB9cGrYsKH+oMTDhw/j/Pnz2LlzJ4C8U6L/7fnnnwcAeHl5ITc3F1lZWSbV0b+pVCq0bdsWQN7ZPUuXLsXevXtx48YN/P7778jMzNS/t3379rCzs9N/r/T0dCiVSvTp0wfDhw/Hc889B39/f3Tt2tWoZx89ehR9+/bV/3kFBwcjNDRUP+epc+fOsLS0BAA0a9YM6enpcHV11Z9i3KVLF3Tp0gUdO3Ys9fcnkgtBEBAQEIC5c+cCADIzMyEIAi5cuFDoANqpU6cavB97aIieYtbW1vr/VigU+p4AX19f6HQ6nDt3Dt999x0GDx5c5OdtbW0B5P3i+e/Bc5IkQafTlfgcAPoGOp9arS70HFEUsXLlSuzevRu7d+/Gjh07Csx7sbKy0t87/9mlZWlpCZUq799yFy5cwLBhw/Do0SP4+fnhtddeK/De4r7X8uXL8fnnn6Nhw4ZYu3Yt3nrrLaOeLYpioWuG6tHCwgJfffUVwsLC4ODggEWLFlXZs6vo6fLss8/iwIEDuHfvHiRJwvvvv49NmzaV+gBaBhqiKmrIkCFYsGABPD09CwyLFKVt27a4fv26fqjj6tWrOHXqFNq3b18mZfH398fGjRshSRJyc3MxadIk/XBUcVQqFQRBeKJwc+rUKXh7e2PMmDFo3749YmNjIQhCiZ9JS0tD165d4eDggNGjR+PNN9/E+fPnC71PqVTqg0q+zp07Izo6Wr/6adeuXXBwcECjRo2Kfd7ly5fRv39/uLu7Y8KECRg9enSRzyOqbJo3b47XX38do0aNQr9+/SCKIsaPHw9ra2v9AbT9+vXDiRMnMGvWLIP345ATUSU3atSoQsNFb731VoF/7Rdl4MCBWLFiBVasWGHwGU5OTli5ciUWLFiAnJwcKBQKhIWFoUmTJiWuMjLWnDlzEBoaisDAQGi1WnTq1KlQb8l/OTs7o3Xr1ujXrx+2bt0KR0dHk5/bv39//PDDDwgICIAoiujWrRvS09Px6NGjYj/j5OSESZMmYfTo0bC2toZSqcTChQsLva9Pnz4YOXIkPv74Y/01Pz8/jB49GqNGjYIoinBycsKaNWuKHO7L17x5cwQEBGDw4MGwtbWFtbW1voueqDI6dOiQ/r+HDBmCIUOGFHpPmzZt9EPQxuKybSIiIqr0OORERERElR4DDREREVV6DDRERERU6THQEBERUaXHQENERESVHgMNERERVXoMNERERFTpMdAQERFRpff/VnUpZ37bX/wAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "num_env_transitions = ROLLOUT_LEN*TRAINING_ITERS*TRAINING_EVAL_ITERS\n",
        "x_values = np.asarray(jnp.arange(0, num_env_transitions, num_env_transitions/len(avg_reward)))\n",
        "avg_reward = np.asarray(avg_reward)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.lineplot(x=x_values, y=avg_reward)\n",
        "plt.xlabel('Environment Transitions')\n",
        "plt.ylabel('Average Reward')\n",
        "plt.title(f'DQN on TSP-v1 - training time: {np.round((total_time)/60, 2)} minutes')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v_flash",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7II68klE8rVe"
      },
      "source": [
        "# Distributed DQN Anakin Agent in `Jumanji` using `flashbax`\n",
        "### [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/instadeepai/flashbax/blob/main/examples/anakin_dqn_example.ipynb)\n",
        "\n",
        "Adapted from [Gymnax Example](https://colab.research.google.com/github/RobertTLange/gymnax/blob/main/examples/01_anakin.ipynb) and DeepMind's [Example Colab](https://colab.research.google.com/drive/1974D-qP17fd5mLxy6QZv-ic4yxlPJp-G?usp=sharing#scrollTo=lhnJkrYLOvcs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n5mRcoAF8rVj",
        "outputId": "877e7822-162c-499c-a9e6-d0a7838faa4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following devices are available:  [CpuDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "import flashbax as fbx\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import jax\n",
        "from jax import random, lax\n",
        "from jax import numpy as jnp\n",
        "from tqdm.auto import tqdm\n",
        "import jax.numpy as jnp\n",
        "import haiku as hk\n",
        "import optax\n",
        "import rlax\n",
        "import timeit\n",
        "import distrax\n",
        "import chex\n",
        "from jumanji.wrappers import AutoResetWrapper\n",
        "import jumanji\n",
        "\n",
        "print(\"The following devices are available: \", jax.devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejJALgNS8rVj"
      },
      "source": [
        "### Anakin DQN Distributed Agent Setup\n",
        "The following is a DQN implementation in the Anakin framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aM1GJ_Pf8rVk"
      },
      "outputs": [],
      "source": [
        "@chex.dataclass(frozen=True)\n",
        "class TimeStep:\n",
        "    observation: chex.Array\n",
        "    action: chex.Array\n",
        "    discount: chex.Array\n",
        "    reward: chex.Array\n",
        "\n",
        "\n",
        "@chex.dataclass(frozen=True)\n",
        "class Params:\n",
        "    online: hk.Params\n",
        "    target: hk.Params\n",
        "    update_count: int\n",
        "\n",
        "\n",
        "def get_network_fn(num_outputs: int):\n",
        "    def network_fn(obs: chex.Array) -> chex.Array:\n",
        "        \"\"\"Outputs action logits.\"\"\"\n",
        "        network = hk.Sequential(\n",
        "            [\n",
        "            hk.Conv2D(32, kernel_shape=2, stride=1),\n",
        "            jax.nn.relu,\n",
        "            hk.Conv2D(32, kernel_shape=2, stride=1),\n",
        "            jax.nn.relu,\n",
        "            hk.Flatten(),\n",
        "            hk.Linear(256),\n",
        "            jax.nn.relu,\n",
        "            hk.Linear(128),\n",
        "            jax.nn.relu,\n",
        "            hk.Linear(num_outputs),\n",
        "            ]\n",
        "        )\n",
        "        return network(obs)\n",
        "\n",
        "    return hk.without_apply_rng(hk.transform(network_fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_learner_fn(\n",
        "    env,\n",
        "    forward_pass,\n",
        "    buffer_fn,\n",
        "    opt_update,\n",
        "    rollout_len,\n",
        "    agent_discount,\n",
        "    iterations,\n",
        "    target_period,\n",
        "    epsilon_schedule_fn,\n",
        "    sgd_steps_per_rollout,\n",
        "):\n",
        "    \"\"\"Returns a learner function that can be used to update parameters.\"\"\"\n",
        "\n",
        "    def rollout_fn(params_state, outer_rng, env_state, env_timestep):\n",
        "        \"\"\"Collects a trajectory from the environment.\"\"\"\n",
        "        def step_fn(env_data, rng):\n",
        "            \"\"\"Steps the environment and collects transition data.\"\"\"\n",
        "            (env_state, env_timestep, params_state) = env_data\n",
        "            obs_tm1 = env_timestep.observation.grid\n",
        "            d_tm1 = env_timestep.discount\n",
        "            q_values_tm1 = forward_pass(params_state.online, jnp.expand_dims(obs_tm1, 0))\n",
        "            a_tm1_dist = distrax.EpsilonGreedy(preferences=q_values_tm1[0], epsilon=epsilon_schedule_fn(params_state.update_count))\n",
        "            a_tm1 = a_tm1_dist.sample(seed=rng)\n",
        "            new_env_state, new_env_timestep = env.step(env_state, a_tm1)  #\n",
        "            r_t = new_env_timestep.reward\n",
        "            return (\n",
        "                new_env_state,\n",
        "                new_env_timestep,\n",
        "                params_state,\n",
        "            ), TimeStep(  # return env state and transition data.\n",
        "                observation=obs_tm1, action=a_tm1, discount=d_tm1, reward=r_t\n",
        "            ) # We line up the observation with its discount, not the discount of the next observation as is usually seen.\n",
        "              # This is so that we know in a transition that discount[1] is the discount of the next observation.\n",
        "              # e.g. indexing is v[t] = reward[t] + discount[t+1]*value[t+1]\n",
        "              # Switching to Sutton and Barto's notation, we would have v[t] = reward[t+1] + discount[t+1]*value[t+1]\n",
        "              # To do this, we would add r_tm1 = env_timestep.reward to the TimeStep dataclass, not the new_env_timestep.reward\n",
        "\n",
        "        step_rngs = jax.random.split(outer_rng, rollout_len)\n",
        "        (env_state, env_timestep, params_state), rollout = lax.scan(\n",
        "            step_fn, (env_state, env_timestep, params_state), step_rngs\n",
        "        )  # trajectory.\n",
        "\n",
        "        return rollout, env_state, env_timestep\n",
        "\n",
        "    def loss_fn(params, target_params, batch):\n",
        "        \"\"\"Computes the loss for a single batch.\"\"\"\n",
        "        # For ease of reading\n",
        "        o_tm1 = batch.first.observation\n",
        "        a_tm1 = batch.first.action.astype(jnp.int32)\n",
        "        r_t = batch.first.reward\n",
        "        d_t = agent_discount * batch.second.discount\n",
        "        o_t = batch.second.observation\n",
        "        # Compute Q-values for current and next states.\n",
        "        q_tm1 = forward_pass(params, o_tm1)\n",
        "        q_t = forward_pass(target_params, o_t)\n",
        "        q_t_select = forward_pass(params, o_t)\n",
        "        # Compute the TD-error.\n",
        "        td_error = jax.vmap(\n",
        "            rlax.double_q_learning\n",
        "        )(  # compute multi-step temporal diff error.\n",
        "            q_tm1=q_tm1,  # predictions.\n",
        "            a_tm1=a_tm1,  # actions.\n",
        "            r_t=r_t,  # rewards.\n",
        "            discount_t=d_t,  # discount.\n",
        "            q_t_value=q_t,  # target values.\n",
        "            q_t_selector=q_t_select,  # selector values.\n",
        "        )\n",
        "        return jnp.mean(jnp.square(td_error))\n",
        "\n",
        "    def update_fn(\n",
        "        params_state: Params, buffer_state, opt_state, rng, env_state, env_timestep\n",
        "    ):\n",
        "        \"\"\"Updates the parameters of the agent.\"\"\"\n",
        "        rng, rollout_rng, update_rng = random.split(rng, 3)\n",
        "\n",
        "        data_rollout, new_env_state, new_env_timestep = rollout_fn(\n",
        "            params_state, rollout_rng, env_state, env_timestep\n",
        "        )  # collect trajectory from environment. This could be one step, or many steps.\n",
        "\n",
        "        buffer_state = buffer_fn.add(buffer_state, data_rollout)  # store trajectory in buffer.\n",
        "\n",
        "        def sgd_step(carry, rng):\n",
        "            \"\"\"Performs a single SGD step.\"\"\"\n",
        "            params_state, opt_state, buffer_state = carry\n",
        "\n",
        "            batch = buffer_fn.sample(buffer_state, rng).experience  # sample batch from buffer.\n",
        "\n",
        "            params, target_params = params_state.online, params_state.target\n",
        "            grads = jax.grad(loss_fn)(  # compute gradient on a single trajectory.\n",
        "                params, target_params, batch\n",
        "            )\n",
        "            grads = lax.pmean(grads, axis_name=\"j\")  # reduce mean across cores.\n",
        "            grads = lax.pmean(grads, axis_name=\"i\")  # reduce mean across batch.\n",
        "            updates, new_opt_state = opt_update(grads, opt_state)  # transform grads.\n",
        "            new_params = optax.apply_updates(params, updates)  # update parameters.\n",
        "            target_params = optax.periodic_update(  # update target parameters.\n",
        "                new_params, target_params, params_state.update_count + 1, target_period\n",
        "            )\n",
        "            new_params_state = Params(  # update parameters state.\n",
        "                online=new_params,\n",
        "                target=target_params,\n",
        "                update_count=params_state.update_count + 1,\n",
        "            )\n",
        "            return (new_params_state, new_opt_state, buffer_state), None\n",
        "\n",
        "        real_update_fn = lambda p_state, o_state, b_state, rng: jax.lax.scan(sgd_step, (p_state, o_state, b_state), jax.random.split(rng, sgd_steps_per_rollout))[0]\n",
        "        fake_update_fn = lambda p_state, o_state, b_state, _: (p_state, o_state, b_state)\n",
        "\n",
        "        new_params_state, new_opt_state, buffer_state = jax.lax.cond(  # conditional update.\n",
        "            buffer_fn.can_sample(buffer_state),  # if buffer can sample.\n",
        "            real_update_fn,  # perform update.\n",
        "            fake_update_fn,  # else do nothing.\n",
        "            params_state,\n",
        "            opt_state,\n",
        "            buffer_state,\n",
        "            update_rng,\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            new_params_state,\n",
        "            buffer_state,\n",
        "            new_opt_state,\n",
        "            rng,\n",
        "            new_env_state,\n",
        "            new_env_timestep,\n",
        "        )\n",
        "\n",
        "    def learner_fn(\n",
        "        params_state: Params, buffer_state, opt_state, rngs, env_states, env_timesteps\n",
        "    ):\n",
        "        \"\"\"Performs multiple SGD steps.\"\"\"\n",
        "        batched_update_fn = jax.vmap(\n",
        "            update_fn, axis_name=\"j\"\n",
        "        )  # vectorize across batch.\n",
        "\n",
        "        def iterate_fn(_, val):  # repeat many times to avoid going back to Python.\n",
        "            params_state, buffer_state, opt_state, rngs, env_states, env_timesteps = val\n",
        "            return batched_update_fn(\n",
        "                params_state, buffer_state, opt_state, rngs, env_states, env_timesteps\n",
        "            )\n",
        "\n",
        "        return lax.fori_loop(\n",
        "            0,\n",
        "            iterations,\n",
        "            iterate_fn,\n",
        "            (params_state, buffer_state, opt_state, rngs, env_states, env_timesteps),\n",
        "        )\n",
        "\n",
        "    return learner_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWdQogrA8rVl"
      },
      "source": [
        "### Create Experiment Fns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g6yNZahR8rVl"
      },
      "outputs": [],
      "source": [
        "def set_up_experiment(\n",
        "    env,\n",
        "    batch_size,\n",
        "    step_size,\n",
        "    seed,\n",
        "    buffer_size,\n",
        "    epsilon_init,\n",
        "    epsilon_final,\n",
        "    epsilon_steps,\n",
        "):\n",
        "    \"\"\"Sets up the experiment.\"\"\"\n",
        "    cores_count = len(jax.devices())  # get available TPU cores.\n",
        "    network = get_network_fn(env.action_spec().num_values)  # define network.\n",
        "    optim = optax.adam(step_size)  # define optimiser.\n",
        "\n",
        "    rng, rng_e, rng_p = random.split(random.PRNGKey(seed), num=3)  # prng keys.\n",
        "    _, timestep = env.reset(rng_e)\n",
        "    obs = timestep.observation.grid\n",
        "    dummy_obs = jnp.expand_dims(obs, 0)  # dummy for net init.\n",
        "    params = network.init(rng_p, dummy_obs)  # initialise params.\n",
        "    opt_state = optim.init(params)  # initialise optimiser stats.\n",
        "    buffer_fn = fbx.make_flat_buffer(\n",
        "        max_length=buffer_size,\n",
        "        min_length=batch_size,\n",
        "        sample_batch_size=batch_size,\n",
        "        add_sequences=True,\n",
        "        add_batch_size=None,\n",
        "    )\n",
        "    buffer_state = buffer_fn.init(\n",
        "        TimeStep(\n",
        "            observation=obs,\n",
        "            action=jnp.zeros((), dtype=jnp.int32),\n",
        "            reward=jnp.zeros(()),\n",
        "            discount=jnp.zeros(()),\n",
        "        )\n",
        "    )  # initialise buffer state.\n",
        "    epsilon_schedule_fn = optax.linear_schedule(\n",
        "        epsilon_init, epsilon_final, epsilon_steps\n",
        "    )  # define epsilon schedule.\n",
        "    return (\n",
        "        cores_count,\n",
        "        network,\n",
        "        optim,\n",
        "        params,\n",
        "        opt_state,\n",
        "        buffer_fn,\n",
        "        buffer_state,\n",
        "        rng,\n",
        "        epsilon_schedule_fn,\n",
        "    )\n",
        "\n",
        "\n",
        "def get_rng_keys(cores_count, num_envs, rng):\n",
        "    \"\"\"Returns a batch of random number generator keys.\"\"\"\n",
        "    rng, *step_rngs = jax.random.split(rng, cores_count * num_envs + 1)\n",
        "    reshape = lambda x: x.reshape((cores_count, num_envs) + x.shape[1:])\n",
        "    step_rngs = reshape(jnp.stack(step_rngs))  # add dimension to pmap over.\n",
        "    return rng, step_rngs\n",
        "\n",
        "\n",
        "def broadcast_to_device_shape(\n",
        "    cores_count, num_envs, params, opt_state, buffer_state, rng\n",
        "):\n",
        "    \"\"\"Broadcasts parameters to device shape.\"\"\"\n",
        "    broadcast = lambda x: jnp.broadcast_to(x, (cores_count, num_envs) + x.shape)\n",
        "    params = jax.tree_map(broadcast, params)  # broadcast to cores and batch.\n",
        "    opt_state = jax.tree_map(broadcast, opt_state)  # broadcast to cores and batch\n",
        "    buffer_state = jax.tree_map(broadcast, buffer_state)  # broadcast to cores and batch\n",
        "    params_state = Params(\n",
        "        online=params,\n",
        "        target=params,\n",
        "        update_count=jnp.zeros(shape=(cores_count, num_envs)),\n",
        "    )\n",
        "    rng, step_rngs = get_rng_keys(cores_count, num_envs, rng)\n",
        "    return params_state, opt_state, buffer_state, step_rngs, rng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLe1Xnpa8rVm"
      },
      "source": [
        "### Create Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "03I-zWqV8rVm"
      },
      "outputs": [],
      "source": [
        "# We separate the environment into a training and evaluation environment. Training resets the environment automatically, while evaluation does not.\n",
        "env = jumanji.make(\"Snake-v1\", num_rows=6, num_cols=6)\n",
        "training_env = AutoResetWrapper(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Uxq0e_8rVm"
      },
      "source": [
        "### Set up Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "prlhq9Tc8rVm"
      },
      "outputs": [],
      "source": [
        "# Number of Training-Evaluation iterations\n",
        "TRAINING_EVAL_ITERS = 10\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-4\n",
        "SEED = 42\n",
        "NUM_ENVS = 8\n",
        "BUFFER_SIZE = 10_000\n",
        "ROLLOUT_LEN = 512\n",
        "SGD_STEPS_PER_ROLLOUT = 64\n",
        "TRAINING_ITERS = 20\n",
        "TARGET_PERIOD = 10\n",
        "AGENT_DISCOUNT = 0.99\n",
        "EPSILON_INIT = 1.0\n",
        "EPSILON_FINAL = 0.1\n",
        "EPSILON_STEPS = 10_000\n",
        "\n",
        "# Evaluation parameters\n",
        "NUM_EVAL_EPISODES = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U89SAavZ8rVm"
      },
      "source": [
        "### Set Up Eval Fns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ROPHsMlF8rVm",
        "outputId": "5d1d727b-a4f9-4fee-fbbf-28bd98b19ab3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ryanp\\anaconda3\\lib\\site-packages\\flashbax\\buffers\\trajectory_buffer.py:473: UserWarning: Setting max_size dynamically sets the `max_length_time_axis` to be `max_size`//`add_batch_size = 10000`.This allows one to control exactly how many timesteps are stored in the buffer.Note that this overrides the `max_length_time_axis` argument.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    cores_count,\n",
        "    network,\n",
        "    optim,\n",
        "    params,\n",
        "    opt_state,\n",
        "    buffer_fn,\n",
        "    buffer_state,\n",
        "    rng,\n",
        "    epsilon_schedule_fn,\n",
        ") = set_up_experiment(\n",
        "    env=training_env,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    step_size=LEARNING_RATE,\n",
        "    seed=SEED,\n",
        "    buffer_size=BUFFER_SIZE,\n",
        "    epsilon_steps=EPSILON_STEPS,\n",
        "    epsilon_init=EPSILON_INIT,\n",
        "    epsilon_final=EPSILON_FINAL,\n",
        ")\n",
        "\n",
        "@jax.jit\n",
        "def eval_one_episode(params, rng):\n",
        "    \"\"\"Evaluates one episode.\"\"\"\n",
        "    state, timestep = env.reset(rng)\n",
        "\n",
        "    def step(val):\n",
        "        params, state, timestep, tot_r, rng, done = val\n",
        "        rng, key_step = jax.random.split(rng)\n",
        "        obs = timestep.observation.grid\n",
        "        q_values = network.apply(params, obs[jnp.newaxis,])\n",
        "        a_t = jnp.argmax(q_values, axis=-1)[0]\n",
        "        state, timestep = env.step(state, a_t)\n",
        "        tot_r += timestep.reward\n",
        "        return (params, state, timestep, tot_r, rng, timestep.last())\n",
        "\n",
        "    params, state, timestep, tot_r, rng, done = jax.lax.while_loop(lambda val : val[5] == False, step, (params, state, timestep, 0, rng, False))\n",
        "\n",
        "    return params, tot_r\n",
        "\n",
        "@jax.jit\n",
        "def eval(params, rng):\n",
        "    \"\"\"Evaluates multiple episodes.\"\"\"\n",
        "    rngs = random.split(rng, NUM_EVAL_EPISODES)\n",
        "    params = jax.tree_map(lambda x: x[0][0], params)\n",
        "    _, tot_r = jax.lax.scan(eval_one_episode, params, rngs)\n",
        "    return tot_r.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml7RZq-08rVn"
      },
      "source": [
        "## Perform Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dVzEOidU8rVn",
        "outputId": "2d512a20-158d-46b1-e940-8e06056e3ca4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f77d1cdac324f86b05e0d4795de5ce8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Reward at iteration 0: 0.6599999666213989\n",
            "Average Reward at iteration 2: 0.9599999785423279\n",
            "Average Reward at iteration 4: 4.119999885559082\n",
            "Average Reward at iteration 6: 7.199999809265137\n",
            "Average Reward at iteration 8: 7.71999979019165\n"
          ]
        }
      ],
      "source": [
        "rng, *env_rngs = jax.random.split(rng, cores_count * NUM_ENVS + 1)\n",
        "env_states, env_timesteps = jax.vmap(env.reset)(jnp.stack(env_rngs))  # init envs.\n",
        "reshape = lambda x: x.reshape((cores_count, NUM_ENVS) + x.shape[1:])\n",
        "env_states = jax.tree_map(reshape, env_states)  # add dimension to pmap over.\n",
        "env_timesteps = jax.tree_map(reshape, env_timesteps)  # add dimension to pmap over.\n",
        "params_state, opt_state, buffer_state, step_rngs, rng = broadcast_to_device_shape(\n",
        "    cores_count, NUM_ENVS, params, opt_state, buffer_state, rng\n",
        ")\n",
        "\n",
        "learn = get_learner_fn(\n",
        "    env=training_env,\n",
        "    forward_pass=network.apply,\n",
        "    buffer_fn=buffer_fn,\n",
        "    opt_update=optim.update,\n",
        "    rollout_len=ROLLOUT_LEN,\n",
        "    agent_discount=AGENT_DISCOUNT,\n",
        "    iterations=TRAINING_ITERS,\n",
        "    target_period=TARGET_PERIOD,\n",
        "    epsilon_schedule_fn=epsilon_schedule_fn,\n",
        "    sgd_steps_per_rollout=SGD_STEPS_PER_ROLLOUT,\n",
        ")\n",
        "learn = jax.pmap(learn, axis_name=\"i\")  # replicate over multiple cores.\n",
        "\n",
        "\n",
        "avg_reward = []\n",
        "total_time = 0\n",
        "for training_eval_iters in tqdm(range(TRAINING_EVAL_ITERS)):\n",
        "    # Train\n",
        "    start = timeit.default_timer()\n",
        "    params_state, buffer_state, opt_state, step_rngs, env_states, env_timesteps = learn(params_state, buffer_state, opt_state, step_rngs, env_states, env_timesteps)\n",
        "    params_state = jax.tree_map(lambda x: x.block_until_ready(), params_state) # wait for params to be ready so time is accurate.\n",
        "    total_time += timeit.default_timer() - start\n",
        "    # Eval\n",
        "    rng, eval_rng = jax.random.split(rng, num=2)\n",
        "    tot_r = eval(params_state.online, eval_rng)\n",
        "    avg_reward.append(tot_r)\n",
        "    if training_eval_iters % 2 == 0:\n",
        "        print(f\"Average Reward at iteration {training_eval_iters}: {tot_r}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJOLnm158rVn"
      },
      "source": [
        "## Plot Evaluation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "64YyUGSh8rVn",
        "outputId": "9d10fc7e-1ef6-426d-a6f8-69fad8773446"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "num_env_transitions = ROLLOUT_LEN*TRAINING_ITERS*TRAINING_EVAL_ITERS\n",
        "x_values = np.asarray(jnp.arange(0, num_env_transitions, num_env_transitions/len(avg_reward)))\n",
        "avg_reward = np.asarray(avg_reward)\n",
        "\n",
        "sns.lineplot(x=x_values, y=avg_reward)\n",
        "plt.xlabel('Environment Transitions')\n",
        "plt.ylabel('Average Reward')\n",
        "plt.title(f'DQN on Snake-v1 - training time: {np.round((total_time)/60, 2)} minutes')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v_flash",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
